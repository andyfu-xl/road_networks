{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMO_HOME found\n",
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import sumolib\n",
    "import traci\n",
    "from sumolib import checkBinary\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data, Batch\n",
    "import sys\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from collections import namedtuple, deque\n",
    "import gym\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import copy\n",
    "from itertools import count\n",
    "\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    print('SUMO_HOME found')\n",
    "    sys.path.append(os.path.join(os.environ['SUMO_HOME'], 'tools'))\n",
    "\n",
    "# sumoBinary = checkBinary('sumo-gui')\n",
    "sumoBinary = checkBinary('sumo')\n",
    "roadNetwork = \"./config/osm.sumocfg\"\n",
    "sumoCmd = [sumoBinary, \"-c\", roadNetwork, \"--start\", \"--quit-on-end\"]\n",
    "# use gpu if available\n",
    "# device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device = torch.device(\"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervehicleConnectivity(threshold = None):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for vehicle in traci.vehicle.getIDList():\n",
    "        x, y = traci.vehicle.getPosition(vehicle)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    xs = torch.tensor(xs, dtype=torch.float32).view(-1,1)\n",
    "    ys = torch.tensor(ys, dtype=torch.float32).view(-1,1)\n",
    "    intervehicle_distances = torch.sqrt((xs - xs.t())**2 + (ys - ys.t())**2)\n",
    "    if threshold is not None:\n",
    "        # make the distances 1 if less than the threshold, 0 otherwise\n",
    "        connectivity = torch.where(intervehicle_distances < threshold, torch.ones_like(intervehicle_distances), torch.zeros_like(intervehicle_distances))\n",
    "    return connectivity, xs, ys, intervehicle_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "def randomTrips(dur=1000, density=12):\n",
    "    os.system(\"python $SUMO_HOME/tools/randomTrips.py -n config/osm.net.xml.gz -r config/osm.passenger.trips.xml -e \" + str(dur) + \" -l --insertion-density=\" + str(density))\n",
    "\n",
    "def shouldContinueSim():\n",
    "    numVehicles = traci.simulation.getMinExpectedNumber()\n",
    "    return True if numVehicles > 0 else False\n",
    "\n",
    "def restart(sumoCmd):\n",
    "    with io.StringIO() as buf, redirect_stdout(buf):\n",
    "        try:\n",
    "            traci.close()\n",
    "        except:\n",
    "            pass\n",
    "        traci.start(sumoCmd)\n",
    "\n",
    "def close():\n",
    "    traci.close()\n",
    "\n",
    "randomTrips(800, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_distance(adj_matrix):\n",
    "    n_hop_matrix = torch.zeros_like(adj_matrix)\n",
    "    for start_node in range(adj_matrix.size(0)):\n",
    "        visited = [0] * adj_matrix.size(0)\n",
    "        queue = deque([(start_node, 0)])\n",
    "        visited[start_node] = 0\n",
    "        \n",
    "        while queue:\n",
    "            current_node, current_dist = queue.popleft()\n",
    "            \n",
    "            for neighbor, connected in enumerate(adj_matrix[current_node]):\n",
    "                if connected and not visited[neighbor]:\n",
    "                    queue.append((neighbor, current_dist + 1))\n",
    "                    visited[neighbor] = True\n",
    "                    n_hop_matrix[start_node, neighbor] = current_dist + 1\n",
    "    \n",
    "    return n_hop_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutingGym(gym.Env):\n",
    "    def __init__(self, sumoCmd, max_steps=1100, n_nodes=57, max_routing_steps=100):\n",
    "        self.sumoCmd = sumoCmd\n",
    "        self.step_counter = 0\n",
    "        self.max_steps = max_steps\n",
    "        self.n_nodes = n_nodes\n",
    "        self.vehicle_ids = None\n",
    "        self.start_node = None\n",
    "        self.end_node = None\n",
    "        self.start_x = None\n",
    "        self.start_y = None\n",
    "        self.end_x = None\n",
    "        self.end_y = None\n",
    "        self.xs = None\n",
    "        self.ys = None\n",
    "        self.visited = torch.zeros(n_nodes)\n",
    "        self.distance_to_end = None\n",
    "        self.current_node = None\n",
    "        self.node_features = None\n",
    "        self.adj_matrix = None\n",
    "        self.edge_index = None\n",
    "        self.hop_thresh = None\n",
    "        self.norm_x = None\n",
    "        self.norm_y = None\n",
    "        self.norm_xy = None\n",
    "        self.routing_done = False\n",
    "        self.rouring_steps = 0\n",
    "        self.min_n_hops = None\n",
    "        self.end_node_indicator = torch.zeros(n_nodes)\n",
    "        self.max_routing_steps = max_routing_steps\n",
    "        self.n_hop_matrix = None\n",
    "        self.neighbors_indicator = None\n",
    "    \n",
    "    def render(self):\n",
    "        self.show_gui = True\n",
    "\n",
    "    def reset(self):\n",
    "        try:\n",
    "            traci.close()\n",
    "        except:\n",
    "            pass\n",
    "        traci.start(sumoCmd)\n",
    "        self.step_counter = 0\n",
    "\n",
    "        while self.step_counter < 400:\n",
    "            traci.simulationStep()\n",
    "            self.step_counter += 1\n",
    "\n",
    "    def step(self):\n",
    "        traci.simulationStep()\n",
    "        self.end_node_indicator = torch.zeros(self.n_nodes)\n",
    "        self.routing_done = False\n",
    "        self.rouring_steps = 0\n",
    "        self.step_counter += 1\n",
    "        self.vehicle_ids = traci.vehicle.getIDList()\n",
    "        self.adj_matrix, self.xs, self.ys, inter_vehicle_distance = intervehicleConnectivity(800)\n",
    "        # we subtract the diagonal to avoid self loops\n",
    "        self.adj_matrix = self.adj_matrix - torch.eye(self.adj_matrix.size(0))\n",
    "        self.adj_matrix = F.pad(self.adj_matrix, (0, self.n_nodes - self.adj_matrix.size(0), 0, self.n_nodes - self.adj_matrix.size(1)), \"constant\", 0)\n",
    "        self.edge_index, _ = dense_to_sparse(self.adj_matrix)\n",
    "        self.select_start_end_nodes()\n",
    "        self.distance_to_end = inter_vehicle_distance[self.end_node]\n",
    "        self.distance_to_end = F.pad(self.distance_to_end, (0, self.n_nodes - self.distance_to_end.size(0)), \"constant\", 0)\n",
    "        self.visited = torch.zeros_like(self.visited)\n",
    "        current_node_indicators = torch.zeros_like(self.visited)\n",
    "        current_node_indicators[self.current_node] = 1\n",
    "        self.end_node_indicator[self.end_node] = 1\n",
    "        self.neighbors_indicator = self.adj_matrix[self.current_node]\n",
    "        self.node_features = torch.stack((self.xs, self.ys, self.visited, current_node_indicators, \n",
    "                                          self.distance_to_end, self.end_node_indicator, self.neighbors_indicator)).T\n",
    "        \n",
    "        return self.node_features.to(device)\n",
    "\n",
    "    def select_start_end_nodes(self):\n",
    "        self.n_hop_matrix = bfs_distance(self.adj_matrix)\n",
    "        self.hop_thresh = min(self.n_hop_matrix.max(), 1)\n",
    "        starts, ends = torch.where(self.n_hop_matrix >= self.hop_thresh)\n",
    "        starts = starts.tolist()\n",
    "        ends = ends.tolist()\n",
    "        self.start_node, self.end_node = random.choice(list(zip(starts, ends)))\n",
    "        # minimal number of hops between start and end nodes\n",
    "        self.min_n_hops = self.n_hop_matrix[starts[0], ends[0]]\n",
    "        self.current_node = self.start_node\n",
    "        # self.start_x = self.xs[self.start_node].item()\n",
    "        # self.start_y = self.ys[self.start_node].item()\n",
    "        # self.end_x = self.xs[self.end_node].item()\n",
    "        # self.end_y = self.ys[self.end_node].item()\n",
    "        # self.norm_x = self.end_x - self.start_x\n",
    "        # self.norm_y = self.end_y - self.start_y\n",
    "        # self.norm_xy = np.sqrt(self.norm_x**2 + self.norm_y**2)\n",
    "\n",
    "        # self.xs = self.xs.squeeze() / self.norm_x\n",
    "        # self.ys = self.ys.squeeze() / self.norm_y\n",
    "        # # padding with zeros\n",
    "        # self.xs = F.pad(self.xs, (0, self.n_nodes - self.xs.size(0)), \"constant\", 0)\n",
    "        # self.ys = F.pad(self.ys, (0, self.n_nodes - self.ys.size(0)), \"constant\", 0)\n",
    "\n",
    "\n",
    "    def act(self, neighbor_index):\n",
    "        self.rouring_steps += 1\n",
    "        neighbors = torch.where(self.adj_matrix[self.current_node] == 1)[0]\n",
    "        valid_action_size = len(neighbors)\n",
    "        if valid_action_size <= neighbor_index:\n",
    "            if self.node_features.device != device:\n",
    "                self.node_features = self.node_features.to(device)\n",
    "            return self.node_features, torch.tensor(0).to(device), False\n",
    "        # check if the next hop is reachable\n",
    "        else:\n",
    "            next_hop = neighbors[neighbor_index]\n",
    "            self.visited[self.current_node] = 1\n",
    "            reward = self.compute_reward(next_hop)\n",
    "            self.current_node = next_hop\n",
    "            curr_node_indicators = torch.zeros_like(self.visited)\n",
    "            curr_node_indicators[self.current_node] = 1\n",
    "            self.neighbors_indicator = self.adj_matrix[self.current_node]\n",
    "            self.node_features = torch.stack((self.xs, self.ys, copy.deepcopy(self.visited), curr_node_indicators, \n",
    "                                              self.distance_to_end, self.end_node_indicator, self.neighbors_indicator)).T\n",
    "            return self.node_features.to(device), torch.tensor(reward).to(device), self.routing_done\n",
    "\n",
    "    \n",
    "    def get_action_mask(self):\n",
    "        action_mask = copy.deepcopy(self.adj_matrix[self.current_node])\n",
    "        action_mask = F.pad(action_mask, (0, self.n_nodes - action_mask.size(0)), \"constant\", 0).to(device)\n",
    "        return action_mask\n",
    "\n",
    "    def get_adj_matrix(self):\n",
    "        return copy.deepcopy(self.adj_matrix).to(device)\n",
    "    \n",
    "    def get_edge_index(self):\n",
    "        return copy.deepcopy(self.edge_index).to(device)\n",
    "        \n",
    "    def compute_reward(self, next_hop):\n",
    "        if self.rouring_steps >= self.max_routing_steps:\n",
    "            print(\"Routing steps exceeded the maximum routing steps, minimum number of hops: \", self.min_n_hops)\n",
    "            self.routing_done = True\n",
    "            return -1\n",
    "        elif next_hop == self.end_node:\n",
    "            print(\"Routing done, number of hops: \", self.rouring_steps, \" minimum number of hops: \", self.min_n_hops)\n",
    "            self.routing_done = True\n",
    "            return self.min_n_hops / self.rouring_steps + 5\n",
    "        elif self.n_hop_matrix[self.current_node, self.end_node] > self.n_hop_matrix[next_hop, self.end_node]:\n",
    "            return 0.1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sim_done(self):\n",
    "        \"\"\"\n",
    "        function: get the done state of simulation.\n",
    "        \"\"\"\n",
    "        return not (shouldContinueSim() and self.step_counter <= self.max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDQN(nn.Module):\n",
    "    def __init__(self, in_channels=7, n_nodes=57, hidden_dim=64, dropout=0.1, max_n_neighbors=15):\n",
    "        super(GDQN, self).__init__()\n",
    "        self.n_nodes = n_nodes\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.convs1 = GCNConv(in_channels, hidden_dim)\n",
    "        self.convs2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(hidden_dim * n_nodes, n_nodes)\n",
    "        self.fc2 = nn.Linear(n_nodes, max_n_neighbors)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.selu = nn.SELU()\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.convs1(x, edge_index)\n",
    "        x = self.selu(x)\n",
    "        x = self.convs2(x, edge_index)\n",
    "        x = self.selu(x)\n",
    "        x = x.view(-1, self.n_nodes * self.hidden_dim)\n",
    "        x = self.fc1(x)\n",
    "        x = self.selu(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('data', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.95\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.00\n",
    "EPS_DECAY = 10000\n",
    "TAU = 0.005\n",
    "LR = 0.01\n",
    "\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_nodes = 57\n",
    "env = RoutingGym(sumoCmd, 1100, n_nodes)\n",
    "# Get the number of state observations\n",
    "\n",
    "policy_net = GDQN().to(device)\n",
    "target_net = GDQN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(1000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(data, action_mask):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            return policy_net(data).max(1).indices.view(-1)\n",
    "    else:\n",
    "        valid_size = len(torch.where(action_mask == 1)[0])\n",
    "        print(valid_size)\n",
    "        return torch.randint(0, valid_size, (1,), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = Batch.from_data_list([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    data_batch = Batch.from_data_list(batch.data)\n",
    "    action_batch = torch.stack(batch.action)\n",
    "    reward_batch = torch.concat(batch.reward)\n",
    "  \n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    state_action_values = policy_net(data_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "***Starting server on port 55631 ***\n",
      "Loading net-file from './config/osm.net.xml.gz' ... done (110ms).\n",
      "Loading done.\n",
      "Simulation version 1.20.0 started with time: 0.00.\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "Routing done, number of hops:  86  minimum number of hops:  tensor(1.)\n",
      "Episode: 1, Accumulated reward: 7.111627705395222\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_20474/637170019.py:116: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return self.node_features.to(device), torch.tensor(reward).to(device), self.routing_done\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "6\n",
      "Routing done, number of hops:  44  minimum number of hops:  tensor(1.)\n",
      "Episode: 2, Accumulated reward: 6.522727511823177\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  5  minimum number of hops:  tensor(1.)\n",
      "Episode: 3, Accumulated reward: 5.199999809265137\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing done, number of hops:  15  minimum number of hops:  tensor(1.)\n",
      "Episode: 4, Accumulated reward: 5.466666609048843\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "4\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "2\n",
      "6\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 5, Accumulated reward: 1.500000037252903\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "4\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "4\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 6, Accumulated reward: 0.9000000283122063\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "3\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "4\n",
      "Routing done, number of hops:  85  minimum number of hops:  tensor(1.)\n",
      "Episode: 7, Accumulated reward: 7.411764562129974\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing done, number of hops:  22  minimum number of hops:  tensor(1.)\n",
      "Episode: 8, Accumulated reward: 5.845454514026642\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "Routing done, number of hops:  11  minimum number of hops:  tensor(1.)\n",
      "Episode: 9, Accumulated reward: 5.190909005701542\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 10, Accumulated reward: 1.3000000342726707\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "5\n",
      "8\n",
      "5\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "8\n",
      "6\n",
      "3\n",
      "4\n",
      "Routing done, number of hops:  27  minimum number of hops:  tensor(1.)\n",
      "Episode: 11, Accumulated reward: 5.837036907672882\n",
      "1\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 12, Accumulated reward: 6.0\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "Routing done, number of hops:  75  minimum number of hops:  tensor(1.)\n",
      "Episode: 13, Accumulated reward: 6.913333348929882\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "4\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  49  minimum number of hops:  tensor(1.)\n",
      "Episode: 14, Accumulated reward: 6.020408168435097\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "6\n",
      "6\n",
      "8\n",
      "5\n",
      "6\n",
      "6\n",
      "8\n",
      "3\n",
      "6\n",
      "8\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "4\n",
      "Routing done, number of hops:  41  minimum number of hops:  tensor(1.)\n",
      "Episode: 15, Accumulated reward: 6.4243902415037155\n",
      "2\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 16, Accumulated reward: 6.0\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 17, Accumulated reward: 6.0\n",
      "6\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 18, Accumulated reward: 6.0\n",
      "8\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  6  minimum number of hops:  tensor(1.)\n",
      "Episode: 19, Accumulated reward: 5.3666665107011795\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "8\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "8\n",
      "7\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "8\n",
      "7\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "7\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "8\n",
      "3\n",
      "3\n",
      "8\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "4\n",
      "4\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "8\n",
      "5\n",
      "4\n",
      "7\n",
      "4\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "8\n",
      "4\n",
      "5\n",
      "4\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "8\n",
      "8\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 20, Accumulated reward: 1.600000038743019\n",
      "3\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 21, Accumulated reward: 6.0\n",
      "5\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 22, Accumulated reward: 6.0\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "Routing done, number of hops:  14  minimum number of hops:  tensor(1.)\n",
      "Episode: 23, Accumulated reward: 5.271428778767586\n",
      "2\n",
      "2\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 24, Accumulated reward: 5.5\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "7\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  10  minimum number of hops:  tensor(1.)\n",
      "Episode: 25, Accumulated reward: 5.399999909102917\n",
      "2\n",
      "2\n",
      "2\n",
      "Routing done, number of hops:  7  minimum number of hops:  tensor(1.)\n",
      "Episode: 26, Accumulated reward: 5.142857074737549\n",
      "6\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 27, Accumulated reward: 6.0\n",
      "4\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 28, Accumulated reward: 5.5\n",
      "5\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 29, Accumulated reward: 6.0\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "Routing done, number of hops:  9  minimum number of hops:  tensor(1.)\n",
      "Episode: 30, Accumulated reward: 5.411111168563366\n",
      "5\n",
      "8\n",
      "6\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  6  minimum number of hops:  tensor(1.)\n",
      "Episode: 31, Accumulated reward: 5.166666507720947\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  19  minimum number of hops:  tensor(1.)\n",
      "Episode: 32, Accumulated reward: 5.452631384134293\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "8\n",
      "5\n",
      "5\n",
      "6\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "Routing done, number of hops:  52  minimum number of hops:  tensor(1.)\n",
      "Episode: 33, Accumulated reward: 6.119230858981609\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "Routing done, number of hops:  4  minimum number of hops:  tensor(1.)\n",
      "Episode: 34, Accumulated reward: 5.450000002980232\n",
      "4\n",
      "2\n",
      "4\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "Routing done, number of hops:  23  minimum number of hops:  tensor(1.)\n",
      "Episode: 35, Accumulated reward: 5.5434784963727\n",
      "5\n",
      "6\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 36, Accumulated reward: 5.600000001490116\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "8\n",
      "5\n",
      "8\n",
      "6\n",
      "7\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  56  minimum number of hops:  tensor(1.)\n",
      "Episode: 37, Accumulated reward: 6.817857101559639\n",
      "3\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "Routing done, number of hops:  5  minimum number of hops:  tensor(1.)\n",
      "Episode: 38, Accumulated reward: 5.499999813735485\n",
      "7\n",
      "6\n",
      "5\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "Routing done, number of hops:  18  minimum number of hops:  tensor(1.)\n",
      "Episode: 39, Accumulated reward: 5.655555352568626\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 40, Accumulated reward: 1.4000000357627869\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 41, Accumulated reward: 1.600000038743019\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "Routing done, number of hops:  53  minimum number of hops:  tensor(1.)\n",
      "Episode: 42, Accumulated reward: 6.118867985904217\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "7\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "7\n",
      "7\n",
      "4\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 43, Accumulated reward: 1.4000000357627869\n",
      "6\n",
      "7\n",
      "8\n",
      "6\n",
      "5\n",
      "2\n",
      "2\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "6\n",
      "5\n",
      "5\n",
      "8\n",
      "4\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 44, Accumulated reward: 1.3000000342726707\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "7\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "4\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "6\n",
      "5\n",
      "7\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "2\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 45, Accumulated reward: 1.2000000327825546\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "5\n",
      "6\n",
      "Routing done, number of hops:  43  minimum number of hops:  tensor(1.)\n",
      "Episode: 46, Accumulated reward: 6.123255841434002\n",
      "3\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 47, Accumulated reward: 5.5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "Routing done, number of hops:  29  minimum number of hops:  tensor(1.)\n",
      "Episode: 48, Accumulated reward: 5.73448296636343\n",
      "5\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 49, Accumulated reward: 2.0000000447034836\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "4\n",
      "7\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "Routing done, number of hops:  65  minimum number of hops:  tensor(1.)\n",
      "Episode: 50, Accumulated reward: 6.71538469940424\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "5\n",
      "3\n",
      "Routing done, number of hops:  12  minimum number of hops:  tensor(1.)\n",
      "Episode: 51, Accumulated reward: 5.583333499729633\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "7\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 52, Accumulated reward: 0.700000025331974\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 53, Accumulated reward: 0.5000000223517418\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "8\n",
      "7\n",
      "6\n",
      "7\n",
      "8\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "8\n",
      "4\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "4\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "8\n",
      "4\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "4\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 54, Accumulated reward: 0.6000000238418579\n",
      "6\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 55, Accumulated reward: 6.0\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "Routing done, number of hops:  12  minimum number of hops:  tensor(1.)\n",
      "Episode: 56, Accumulated reward: 5.483333498239517\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "4\n",
      "7\n",
      "8\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "8\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "5\n",
      "4\n",
      "5\n",
      "7\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 57, Accumulated reward: 0.9000000283122063\n",
      "6\n",
      "6\n",
      "7\n",
      "8\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "Routing done, number of hops:  16  minimum number of hops:  tensor(1.)\n",
      "Episode: 58, Accumulated reward: 5.562500007450581\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "5\n",
      "4\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 59, Accumulated reward: 0.6000000238418579\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "Routing done, number of hops:  7  minimum number of hops:  tensor(1.)\n",
      "Episode: 60, Accumulated reward: 5.342857077717781\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "7\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "4\n",
      "5\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "5\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "5\n",
      "7\n",
      "8\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "8\n",
      "5\n",
      "4\n",
      "4\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 61, Accumulated reward: 1.1000000312924385\n",
      "4\n",
      "8\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "Routing done, number of hops:  25  minimum number of hops:  tensor(1.)\n",
      "Episode: 62, Accumulated reward: 5.839999973773956\n",
      "3\n",
      "3\n",
      "Routing done, number of hops:  3  minimum number of hops:  tensor(1.)\n",
      "Episode: 63, Accumulated reward: 5.333333492279053\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 64, Accumulated reward: 0.6000000238418579\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "7\n",
      "8\n",
      "7\n",
      "6\n",
      "7\n",
      "8\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 65, Accumulated reward: 0.5000000223517418\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  32  minimum number of hops:  tensor(1.)\n",
      "Episode: 66, Accumulated reward: 5.331250004470348\n",
      "6\n",
      "8\n",
      "8\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  37  minimum number of hops:  tensor(1.)\n",
      "Episode: 67, Accumulated reward: 5.62702713906765\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "Routing done, number of hops:  32  minimum number of hops:  tensor(1.)\n",
      "Episode: 68, Accumulated reward: 5.4312500059604645\n",
      "6\n",
      "8\n",
      "4\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "7\n",
      "5\n",
      "7\n",
      "8\n",
      "Routing done, number of hops:  13  minimum number of hops:  tensor(1.)\n",
      "Episode: 69, Accumulated reward: 5.476922899484634\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "5\n",
      "6\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "3\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "8\n",
      "5\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "Routing done, number of hops:  80  minimum number of hops:  tensor(1.)\n",
      "Episode: 70, Accumulated reward: 6.612499833106995\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "4\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing done, number of hops:  37  minimum number of hops:  tensor(1.)\n",
      "Episode: 71, Accumulated reward: 6.027027145028114\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "7\n",
      "8\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 72, Accumulated reward: 1.1000000312924385\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 73, Accumulated reward: 1.2000000327825546\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  13  minimum number of hops:  tensor(1.)\n",
      "Episode: 74, Accumulated reward: 5.376922897994518\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "6\n",
      "7\n",
      "8\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "8\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 75, Accumulated reward: 1.0000000298023224\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "8\n",
      "7\n",
      "6\n",
      "4\n",
      "4\n",
      "Routing done, number of hops:  27  minimum number of hops:  tensor(1.)\n",
      "Episode: 76, Accumulated reward: 5.63703690469265\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "Routing done, number of hops:  24  minimum number of hops:  tensor(1.)\n",
      "Episode: 77, Accumulated reward: 5.541666515171528\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 78, Accumulated reward: 1.1000000312924385\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "Routing done, number of hops:  19  minimum number of hops:  tensor(1.)\n",
      "Episode: 79, Accumulated reward: 5.852631390094757\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  68  minimum number of hops:  tensor(1.)\n",
      "Episode: 80, Accumulated reward: 6.614705681800842\n",
      "2\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing done, number of hops:  20  minimum number of hops:  tensor(1.)\n",
      "Episode: 81, Accumulated reward: 5.550000198185444\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing done, number of hops:  8  minimum number of hops:  tensor(1.)\n",
      "Episode: 82, Accumulated reward: 5.325000002980232\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "5\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "4\n",
      "Routing done, number of hops:  63  minimum number of hops:  tensor(1.)\n",
      "Episode: 83, Accumulated reward: 7.015872985124588\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "3\n",
      "Routing done, number of hops:  12  minimum number of hops:  tensor(1.)\n",
      "Episode: 84, Accumulated reward: 5.283333495259285\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 85, Accumulated reward: 1.600000038743019\n",
      "4\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "7\n",
      "5\n",
      "7\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "Routing done, number of hops:  60  minimum number of hops:  tensor(1.)\n",
      "Episode: 86, Accumulated reward: 6.616666913032532\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  54  minimum number of hops:  tensor(1.)\n",
      "Episode: 87, Accumulated reward: 6.518518470227718\n",
      "4\n",
      "4\n",
      "Routing done, number of hops:  3  minimum number of hops:  tensor(1.)\n",
      "Episode: 88, Accumulated reward: 5.433333493769169\n",
      "6\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing done, number of hops:  23  minimum number of hops:  tensor(1.)\n",
      "Episode: 89, Accumulated reward: 5.443478494882584\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing done, number of hops:  15  minimum number of hops:  tensor(1.)\n",
      "Episode: 90, Accumulated reward: 5.666666612029076\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "4\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "6\n",
      "3\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 91, Accumulated reward: 0.6000000238418579\n",
      "3\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "8\n",
      "7\n",
      "8\n",
      "6\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "5\n",
      "5\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "6\n",
      "9\n",
      "6\n",
      "8\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 92, Accumulated reward: 0.20000001788139343\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing done, number of hops:  8  minimum number of hops:  tensor(1.)\n",
      "Episode: 93, Accumulated reward: 5.125\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "6\n",
      "8\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "7\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "8\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "7\n",
      "9\n",
      "9\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 94, Accumulated reward: 1.0000000298023224\n",
      "3\n",
      "7\n",
      "8\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "7\n",
      "Routing done, number of hops:  14  minimum number of hops:  tensor(1.)\n",
      "Episode: 95, Accumulated reward: 5.271428778767586\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "Routing done, number of hops:  13  minimum number of hops:  tensor(1.)\n",
      "Episode: 96, Accumulated reward: 5.5769229009747505\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "8\n",
      "6\n",
      "9\n",
      "9\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "9\n",
      "9\n",
      "7\n",
      "4\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "7\n",
      "7\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 97, Accumulated reward: 1.0000000298023224\n",
      "9\n",
      "6\n",
      "8\n",
      "8\n",
      "6\n",
      "7\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "8\n",
      "7\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "8\n",
      "3\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "3\n",
      "4\n",
      "6\n",
      "9\n",
      "Routing done, number of hops:  68  minimum number of hops:  tensor(1.)\n",
      "Episode: 98, Accumulated reward: 6.014705672860146\n",
      "2\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 99, Accumulated reward: 5.5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 100, Accumulated reward: 1.500000037252903\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "9\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 101, Accumulated reward: 1.600000038743019\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  10  minimum number of hops:  tensor(1.)\n",
      "Episode: 102, Accumulated reward: 5.099999904632568\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "9\n",
      "6\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 103, Accumulated reward: 0.30000001937150955\n",
      "6\n",
      "9\n",
      "9\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "7\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "7\n",
      "7\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "9\n",
      "7\n",
      "9\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "7\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 104, Accumulated reward: 0.10000001639127731\n",
      "6\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  51  minimum number of hops:  tensor(1.)\n",
      "Episode: 105, Accumulated reward: 6.419608041644096\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "5\n",
      "6\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 106, Accumulated reward: 0.8000000268220901\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  50  minimum number of hops:  tensor(1.)\n",
      "Episode: 107, Accumulated reward: 5.919999994337559\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "6\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "6\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 108, Accumulated reward: 0.8000000268220901\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "9\n",
      "Routing done, number of hops:  9  minimum number of hops:  tensor(1.)\n",
      "Episode: 109, Accumulated reward: 5.111111164093018\n",
      "5\n",
      "4\n",
      "5\n",
      "Routing done, number of hops:  4  minimum number of hops:  tensor(1.)\n",
      "Episode: 110, Accumulated reward: 5.350000001490116\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "7\n",
      "6\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "6\n",
      "7\n",
      "9\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 111, Accumulated reward: 0.40000002086162567\n",
      "7\n",
      "7\n",
      "7\n",
      "10\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "10\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "10\n",
      "7\n",
      "8\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "8\n",
      "7\n",
      "Routing done, number of hops:  68  minimum number of hops:  tensor(1.)\n",
      "Episode: 112, Accumulated reward: 5.9147056713700294\n",
      "10\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "10\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "10\n",
      "7\n",
      "8\n",
      "10\n",
      "6\n",
      "6\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "10\n",
      "7\n",
      "6\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 113, Accumulated reward: 0.10000001639127731\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "10\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "10\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 114, Accumulated reward: -0.29999998956918716\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  10  minimum number of hops:  tensor(1.)\n",
      "Episode: 115, Accumulated reward: 5.399999909102917\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  14  minimum number of hops:  tensor(1.)\n",
      "Episode: 116, Accumulated reward: 5.471428781747818\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "2\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 117, Accumulated reward: 1.500000037252903\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "7\n",
      "Routing done, number of hops:  28  minimum number of hops:  tensor(1.)\n",
      "Episode: 118, Accumulated reward: 5.435714155435562\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "7\n",
      "9\n",
      "9\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "10\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 119, Accumulated reward: 0.40000002086162567\n",
      "9\n",
      "8\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "10\n",
      "5\n",
      "10\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 120, Accumulated reward: 0.10000001639127731\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "5\n",
      "4\n",
      "6\n",
      "2\n",
      "2\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "2\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 121, Accumulated reward: 1.2000000327825546\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  23  minimum number of hops:  tensor(1.)\n",
      "Episode: 122, Accumulated reward: 5.443478494882584\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "7\n",
      "10\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "10\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "7\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "7\n",
      "10\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 123, Accumulated reward: 0.40000002086162567\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 124, Accumulated reward: 6.0\n",
      "2\n",
      "2\n",
      "Routing done, number of hops:  5  minimum number of hops:  tensor(1.)\n",
      "Episode: 125, Accumulated reward: 5.199999809265137\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 126, Accumulated reward: 6.0\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "5\n",
      "5\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "7\n",
      "7\n",
      "9\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 127, Accumulated reward: 0.40000002086162567\n",
      "2\n",
      "2\n",
      "Routing done, number of hops:  6  minimum number of hops:  tensor(1.)\n",
      "Episode: 128, Accumulated reward: 5.166666507720947\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  41  minimum number of hops:  tensor(1.)\n",
      "Episode: 129, Accumulated reward: 5.924390234053135\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 130, Accumulated reward: -0.29999998956918716\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing done, number of hops:  44  minimum number of hops:  tensor(1.)\n",
      "Episode: 131, Accumulated reward: 5.922727502882481\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "9\n",
      "8\n",
      "6\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  67  minimum number of hops:  tensor(1.)\n",
      "Episode: 132, Accumulated reward: 6.514925502240658\n",
      "2\n",
      "2\n",
      "2\n",
      "Routing done, number of hops:  11  minimum number of hops:  tensor(1.)\n",
      "Episode: 133, Accumulated reward: 5.090909004211426\n",
      "3\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 134, Accumulated reward: 5.5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 135, Accumulated reward: -0.19999998807907104\n",
      "6\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  25  minimum number of hops:  tensor(1.)\n",
      "Episode: 136, Accumulated reward: 5.639999970793724\n",
      "4\n",
      "9\n",
      "9\n",
      "6\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 137, Accumulated reward: 0.9000000283122063\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 138, Accumulated reward: -0.3999999910593033\n",
      "8\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "6\n",
      "Routing done, number of hops:  14  minimum number of hops:  tensor(1.)\n",
      "Episode: 139, Accumulated reward: 5.17142877727747\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "8\n",
      "9\n",
      "9\n",
      "Routing done, number of hops:  41  minimum number of hops:  tensor(1.)\n",
      "Episode: 140, Accumulated reward: 6.224390238523483\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "Routing done, number of hops:  19  minimum number of hops:  tensor(1.)\n",
      "Episode: 141, Accumulated reward: 5.3526313826441765\n",
      "9\n",
      "9\n",
      "8\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "Routing done, number of hops:  48  minimum number of hops:  tensor(1.)\n",
      "Episode: 142, Accumulated reward: 6.020833507180214\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing done, number of hops:  10  minimum number of hops:  tensor(1.)\n",
      "Episode: 143, Accumulated reward: 5.099999904632568\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  9  minimum number of hops:  tensor(1.)\n",
      "Episode: 144, Accumulated reward: 5.31111116707325\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  58  minimum number of hops:  tensor(1.)\n",
      "Episode: 145, Accumulated reward: 5.8172414898872375\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "3\n",
      "2\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "Routing done, number of hops:  77  minimum number of hops:  tensor(1.)\n",
      "Episode: 146, Accumulated reward: 7.012987166643143\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 147, Accumulated reward: -0.29999998956918716\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 148, Accumulated reward: 5.600000001490116\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 149, Accumulated reward: 6.0\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 150, Accumulated reward: -0.09999998658895493\n",
      "2\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "Routing done, number of hops:  29  minimum number of hops:  tensor(1.)\n",
      "Episode: 151, Accumulated reward: 5.834482967853546\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 152, Accumulated reward: 6.0\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "6\n",
      "6\n",
      "8\n",
      "8\n",
      "7\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "7\n",
      "4\n",
      "7\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 153, Accumulated reward: 0.40000002086162567\n",
      "7\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "9\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "6\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "8\n",
      "9\n",
      "6\n",
      "8\n",
      "8\n",
      "10\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 154, Accumulated reward: 0.30000001937150955\n",
      "6\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 155, Accumulated reward: 5.600000001490116\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "10\n",
      "9\n",
      "11\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "11\n",
      "10\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 156, Accumulated reward: 0.30000001937150955\n",
      "10\n",
      "10\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "8\n",
      "11\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 157, Accumulated reward: 0.10000001639127731\n",
      "9\n",
      "9\n",
      "Routing done, number of hops:  5  minimum number of hops:  tensor(1.)\n",
      "Episode: 158, Accumulated reward: 5.299999810755253\n",
      "9\n",
      "10\n",
      "8\n",
      "9\n",
      "9\n",
      "7\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "3\n",
      "3\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "11\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 159, Accumulated reward: 0.700000025331974\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "11\n",
      "7\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "5\n",
      "9\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 160, Accumulated reward: 1.0000000298023224\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 161, Accumulated reward: 0.9000000283122063\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing done, number of hops:  16  minimum number of hops:  tensor(1.)\n",
      "Episode: 162, Accumulated reward: 5.0625\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 163, Accumulated reward: 0.700000025331974\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 164, Accumulated reward: 0.700000025331974\n",
      "9\n",
      "12\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "12\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 165, Accumulated reward: 1.3000000342726707\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 166, Accumulated reward: 6.0\n",
      "3\n",
      "9\n",
      "7\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "10\n",
      "10\n",
      "8\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 167, Accumulated reward: 0.6000000238418579\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 168, Accumulated reward: 0.9000000283122063\n",
      "3\n",
      "7\n",
      "3\n",
      "9\n",
      "12\n",
      "9\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "9\n",
      "Routing done, number of hops:  43  minimum number of hops:  tensor(1.)\n",
      "Episode: 169, Accumulated reward: 5.7232558354735374\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "10\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "8\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 170, Accumulated reward: 1.4901161193847656e-08\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "10\n",
      "9\n",
      "10\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "6\n",
      "3\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 171, Accumulated reward: 0.9000000283122063\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing done, number of hops:  33  minimum number of hops:  tensor(1.)\n",
      "Episode: 172, Accumulated reward: 5.430303007364273\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "6\n",
      "9\n",
      "9\n",
      "13\n",
      "13\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "Routing done, number of hops:  58  minimum number of hops:  tensor(1.)\n",
      "Episode: 173, Accumulated reward: 5.717241488397121\n",
      "4\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "13\n",
      "3\n",
      "3\n",
      "3\n",
      "8\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 174, Accumulated reward: 1.0000000298023224\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 175, Accumulated reward: 0.20000001788139343\n",
      "11\n",
      "11\n",
      "10\n",
      "7\n",
      "11\n",
      "13\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "4\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "4\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 176, Accumulated reward: 1.1000000312924385\n",
      "4\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "10\n",
      "10\n",
      "9\n",
      "10\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 177, Accumulated reward: 0.700000025331974\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing done, number of hops:  5  minimum number of hops:  tensor(1.)\n",
      "Episode: 178, Accumulated reward: 5.199999809265137\n",
      "5\n",
      "4\n",
      "5\n",
      "Routing done, number of hops:  4  minimum number of hops:  tensor(1.)\n",
      "Episode: 179, Accumulated reward: 5.25\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "11\n",
      "9\n",
      "11\n",
      "9\n",
      "8\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "10\n",
      "10\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 180, Accumulated reward: 0.40000002086162567\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "13\n",
      "9\n",
      "Routing done, number of hops:  17  minimum number of hops:  tensor(1.)\n",
      "Episode: 181, Accumulated reward: 5.258823588490486\n",
      "10\n",
      "8\n",
      "4\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "13\n",
      "10\n",
      "4\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "8\n",
      "12\n",
      "10\n",
      "13\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "5\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 182, Accumulated reward: 0.40000002086162567\n",
      "4\n",
      "6\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 183, Accumulated reward: 5.600000001490116\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "12\n",
      "12\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 184, Accumulated reward: 0.10000001639127731\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "13\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 185, Accumulated reward: 0.30000001937150955\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "13\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "13\n",
      "9\n",
      "9\n",
      "13\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "4\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 186, Accumulated reward: 0.9000000283122063\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 187, Accumulated reward: -0.7999999970197678\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 188, Accumulated reward: 0.8000000268220901\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "13\n",
      "9\n",
      "12\n",
      "9\n",
      "10\n",
      "13\n",
      "9\n",
      "9\n",
      "14\n",
      "14\n",
      "9\n",
      "9\n",
      "13\n",
      "13\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "4\n",
      "3\n",
      "4\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 189, Accumulated reward: 0.30000001937150955\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "14\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "13\n",
      "10\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 190, Accumulated reward: 0.40000002086162567\n",
      "14\n",
      "8\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "13\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "13\n",
      "9\n",
      "10\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 191, Accumulated reward: -0.3999999910593033\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "10\n",
      "9\n",
      "9\n",
      "13\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 192, Accumulated reward: 0.10000001639127731\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "10\n",
      "5\n",
      "9\n",
      "Routing done, number of hops:  23  minimum number of hops:  tensor(1.)\n",
      "Episode: 193, Accumulated reward: 5.243478491902351\n",
      "12\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 194, Accumulated reward: 5.5\n",
      "6\n",
      "9\n",
      "9\n",
      "12\n",
      "8\n",
      "9\n",
      "10\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "8\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "6\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 195, Accumulated reward: 1.1000000312924385\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "6\n",
      "6\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "14\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 196, Accumulated reward: 0.6000000238418579\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "Routing done, number of hops:  29  minimum number of hops:  tensor(1.)\n",
      "Episode: 197, Accumulated reward: 5.434482961893082\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "14\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "14\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "12\n",
      "14\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "12\n",
      "Routing done, number of hops:  74  minimum number of hops:  tensor(1.)\n",
      "Episode: 198, Accumulated reward: 6.21351358294487\n",
      "9\n",
      "12\n",
      "12\n",
      "7\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "12\n",
      "9\n",
      "12\n",
      "12\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "12\n",
      "9\n",
      "9\n",
      "10\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "7\n",
      "3\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 199, Accumulated reward: 1.4901161193847656e-08\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "6\n",
      "3\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "3\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 200, Accumulated reward: -0.29999998956918716\n",
      "4\n",
      "3\n",
      "5\n",
      "Routing done, number of hops:  7  minimum number of hops:  tensor(1.)\n",
      "Episode: 201, Accumulated reward: 5.242857076227665\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 202, Accumulated reward: 6.0\n",
      "4\n",
      "4\n",
      "4\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "11\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 203, Accumulated reward: 0.30000001937150955\n",
      "3\n",
      "7\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "9\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 204, Accumulated reward: 0.9000000283122063\n",
      "2\n",
      "3\n",
      "3\n",
      "5\n",
      "3\n",
      "5\n",
      "4\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 205, Accumulated reward: 0.20000001788139343\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "12\n",
      "11\n",
      "11\n",
      "11\n",
      "8\n",
      "11\n",
      "11\n",
      "8\n",
      "8\n",
      "10\n",
      "7\n",
      "3\n",
      "7\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 206, Accumulated reward: 0.6000000238418579\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "9\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "7\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 207, Accumulated reward: 0.20000001788139343\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "8\n",
      "8\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 208, Accumulated reward: 1.4901161193847656e-08\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "9\n",
      "8\n",
      "10\n",
      "8\n",
      "12\n",
      "8\n",
      "12\n",
      "10\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 209, Accumulated reward: -0.5999999940395355\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "4\n",
      "4\n",
      "4\n",
      "8\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 210, Accumulated reward: -0.09999998658895493\n",
      "3\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  8  minimum number of hops:  tensor(1.)\n",
      "Episode: 211, Accumulated reward: 5.5250000059604645\n",
      "8\n",
      "10\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "10\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "4\n",
      "4\n",
      "6\n",
      "7\n",
      "10\n",
      "11\n",
      "9\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 212, Accumulated reward: 0.30000001937150955\n",
      "10\n",
      "8\n",
      "10\n",
      "8\n",
      "Routing done, number of hops:  8  minimum number of hops:  tensor(1.)\n",
      "Episode: 213, Accumulated reward: 5.225000001490116\n",
      "10\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "Routing done, number of hops:  58  minimum number of hops:  tensor(1.)\n",
      "Episode: 214, Accumulated reward: 5.517241485416889\n",
      "8\n",
      "11\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "5\n",
      "8\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 215, Accumulated reward: 0.10000001639127731\n",
      "10\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "8\n",
      "9\n",
      "7\n",
      "7\n",
      "Routing done, number of hops:  28  minimum number of hops:  tensor(1.)\n",
      "Episode: 216, Accumulated reward: 5.535714156925678\n",
      "8\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "8\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 217, Accumulated reward: 0.5000000223517418\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "10\n",
      "10\n",
      "10\n",
      "9\n",
      "10\n",
      "10\n",
      "10\n",
      "7\n",
      "Routing done, number of hops:  77  minimum number of hops:  tensor(1.)\n",
      "Episode: 218, Accumulated reward: 5.612987145781517\n",
      "6\n",
      "6\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "12\n",
      "6\n",
      "Routing done, number of hops:  47  minimum number of hops:  tensor(1.)\n",
      "Episode: 219, Accumulated reward: 5.221276476979256\n",
      "12\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 220, Accumulated reward: 1.4901161193847656e-08\n",
      "9\n",
      "9\n",
      "8\n",
      "12\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "9\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "3\n",
      "5\n",
      "5\n",
      "4\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 221, Accumulated reward: -0.29999998956918716\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "12\n",
      "6\n",
      "6\n",
      "9\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 222, Accumulated reward: 0.30000001937150955\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "12\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "11\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 223, Accumulated reward: -0.29999998956918716\n",
      "5\n",
      "8\n",
      "Routing done, number of hops:  3  minimum number of hops:  tensor(1.)\n",
      "Episode: 224, Accumulated reward: 5.433333493769169\n",
      "8\n",
      "8\n",
      "8\n",
      "8\n",
      "5\n",
      "10\n",
      "8\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "12\n",
      "7\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 225, Accumulated reward: -0.19999998807907104\n",
      "4\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 226, Accumulated reward: 6.0\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "8\n",
      "Routing done, number of hops:  93  minimum number of hops:  tensor(1.)\n",
      "Episode: 227, Accumulated reward: 6.410752698779106\n",
      "7\n",
      "7\n",
      "7\n",
      "7\n",
      "Routing done, number of hops:  8  minimum number of hops:  tensor(1.)\n",
      "Episode: 228, Accumulated reward: 5.425000004470348\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 229, Accumulated reward: 0.6000000238418579\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  84  minimum number of hops:  tensor(1.)\n",
      "Episode: 230, Accumulated reward: 6.411904737353325\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "10\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "6\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 231, Accumulated reward: 0.6000000238418579\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "8\n",
      "9\n",
      "9\n",
      "Routing done, number of hops:  59  minimum number of hops:  tensor(1.)\n",
      "Episode: 232, Accumulated reward: 5.616949185729027\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing done, number of hops:  64  minimum number of hops:  tensor(1.)\n",
      "Episode: 233, Accumulated reward: 6.015625014901161\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 234, Accumulated reward: 0.20000001788139343\n",
      "9\n",
      "9\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "6\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 235, Accumulated reward: -0.09999998658895493\n",
      "5\n",
      "5\n",
      "Routing done, number of hops:  17  minimum number of hops:  tensor(1.)\n",
      "Episode: 236, Accumulated reward: 5.058823585510254\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 237, Accumulated reward: -0.6999999955296516\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "2\n",
      "2\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 238, Accumulated reward: 0.40000002086162567\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "5\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "7\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 239, Accumulated reward: 1.4901161193847656e-08\n",
      "5\n",
      "5\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "9\n",
      "9\n",
      "10\n",
      "Routing done, number of hops:  91  minimum number of hops:  tensor(1.)\n",
      "Episode: 240, Accumulated reward: 6.510989211499691\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing done, number of hops:  31  minimum number of hops:  tensor(1.)\n",
      "Episode: 241, Accumulated reward: 5.432258039712906\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "5\n",
      "2\n",
      "5\n",
      "Routing done, number of hops:  94  minimum number of hops:  tensor(1.)\n",
      "Episode: 242, Accumulated reward: 6.110638253390789\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 243, Accumulated reward: 0.10000001639127731\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 244, Accumulated reward: -0.19999998807907104\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "4\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "4\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 245, Accumulated reward: 0.10000001639127731\n",
      "4\n",
      "5\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 246, Accumulated reward: 0.6000000238418579\n",
      "9\n",
      "9\n",
      "9\n",
      "10\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "9\n",
      "Routing done, number of hops:  54  minimum number of hops:  tensor(1.)\n",
      "Episode: 247, Accumulated reward: 5.8185184597969055\n",
      "4\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "3\n",
      "3\n",
      "3\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 248, Accumulated reward: -0.3999999910593033\n",
      "8\n",
      "9\n",
      "9\n",
      "9\n",
      "11\n",
      "9\n",
      "9\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "4\n",
      "2\n",
      "2\n",
      "2\n",
      "2\n",
      "4\n",
      "9\n",
      "9\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 249, Accumulated reward: 1.4901161193847656e-08\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  40  minimum number of hops:  tensor(1.)\n",
      "Episode: 250, Accumulated reward: 5.125000096857548\n",
      "10\n",
      "6\n",
      "6\n",
      "Routing done, number of hops:  6  minimum number of hops:  tensor(1.)\n",
      "Episode: 251, Accumulated reward: 5.266666509211063\n",
      "4\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "12\n",
      "10\n",
      "10\n",
      "10\n",
      "10\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 252, Accumulated reward: 1.4901161193847656e-08\n",
      "10\n",
      "10\n",
      "Routing done, number of hops:  2  minimum number of hops:  tensor(1.)\n",
      "Episode: 253, Accumulated reward: 5.5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "5\n",
      "6\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 254, Accumulated reward: -0.09999998658895493\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 255, Accumulated reward: 1.4901161193847656e-08\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "13\n",
      "11\n",
      "11\n",
      "11\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 256, Accumulated reward: 1.4901161193847656e-08\n",
      "10\n",
      "10\n",
      "11\n",
      "11\n",
      "13\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "10\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "10\n",
      "11\n",
      "13\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 257, Accumulated reward: 0.20000001788139343\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "Routing done, number of hops:  21  minimum number of hops:  tensor(1.)\n",
      "Episode: 258, Accumulated reward: 5.147618867456913\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "11\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 259, Accumulated reward: 0.6000000238418579\n",
      "4\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 260, Accumulated reward: 0.10000001639127731\n",
      "2\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 261, Accumulated reward: 6.0\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 262, Accumulated reward: 0.30000001937150955\n",
      "4\n",
      "6\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 263, Accumulated reward: 0.40000002086162567\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "5\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 264, Accumulated reward: -0.3999999910593033\n",
      "13\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "13\n",
      "12\n",
      "12\n",
      "12\n",
      "11\n",
      "10\n",
      "10\n",
      "11\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 265, Accumulated reward: -0.09999998658895493\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "6\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 266, Accumulated reward: 0.30000001937150955\n",
      "13\n",
      "10\n",
      "10\n",
      "Routing done, number of hops:  16  minimum number of hops:  tensor(1.)\n",
      "Episode: 267, Accumulated reward: 5.162500001490116\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "10\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "5\n",
      "6\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 268, Accumulated reward: -0.19999998807907104\n",
      "2\n",
      "Routing done, number of hops:  1  minimum number of hops:  tensor(1.)\n",
      "Episode: 269, Accumulated reward: 6.0\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 270, Accumulated reward: -0.3999999910593033\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 271, Accumulated reward: -0.19999998807907104\n",
      "12\n",
      "12\n",
      "13\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "12\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 272, Accumulated reward: -0.19999998807907104\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 273, Accumulated reward: 0.20000001788139343\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 274, Accumulated reward: -0.09999998658895493\n",
      "4\n",
      "4\n",
      "5\n",
      "4\n",
      "4\n",
      "4\n",
      "Routing done, number of hops:  32  minimum number of hops:  tensor(1.)\n",
      "Episode: 275, Accumulated reward: 5.231250002980232\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "3\n",
      "4\n",
      "5\n",
      "4\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 276, Accumulated reward: 0.40000002086162567\n",
      "10\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "13\n",
      "Routing steps exceeded the maximum routing steps, minimum number of hops:  tensor(1.)\n",
      "Episode: 277, Accumulated reward: -0.19999998807907104\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "# Initialize the environment and get its state\n",
    "n_epoch = 10\n",
    "for e in range(n_epoch):\n",
    "    env.reset()\n",
    "    done = False\n",
    "    episode_num = 0\n",
    "    while not done:\n",
    "        done = env.sim_done()\n",
    "        state = env.step()\n",
    "        episode_num += 1\n",
    "        edge_index = env.get_edge_index()\n",
    "        routing_done = False\n",
    "        accumulated_reward = 0\n",
    "        while not routing_done:\n",
    "            action_mask = env.get_action_mask()\n",
    "            data = Data(x=state, edge_index=edge_index)\n",
    "            action = select_action(data, action_mask)\n",
    "            node_features, reward, routing_done = env.act(action.item())\n",
    "            reward = torch.tensor([reward], device=device)\n",
    "            accumulated_reward += reward.item()\n",
    "\n",
    "            routing_done = routing_done\n",
    "\n",
    "            if routing_done:\n",
    "                next_state = None\n",
    "                memory.push(data, action, None, reward)\n",
    "            else:\n",
    "                next_state = node_features\n",
    "                memory.push(data, action, Data(x=next_state, edge_index=edge_index), reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the policy network)\n",
    "            optimize_model()\n",
    "\n",
    "            # Soft update of the target network's weights\n",
    "            # θ′ ← τ θ + (1 −τ )θ′\n",
    "            target_net_state_dict = target_net.state_dict()\n",
    "            policy_net_state_dict = policy_net.state_dict()\n",
    "            for key in policy_net_state_dict:\n",
    "                target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "            target_net.load_state_dict(target_net_state_dict)\n",
    "        print(f\"Episode: {episode_num}, Accumulated reward: {accumulated_reward}\")\n",
    "\n",
    "print('Complete')\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
