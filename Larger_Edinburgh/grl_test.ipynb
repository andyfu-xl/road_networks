{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMO_HOME found\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import sumolib\n",
    "import traci\n",
    "from sumolib import checkBinary\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import sys\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from collections import namedtuple, deque\n",
    "import gym\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import copy\n",
    "from itertools import count\n",
    "\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    print('SUMO_HOME found')\n",
    "    sys.path.append(os.path.join(os.environ['SUMO_HOME'], 'tools'))\n",
    "\n",
    "# sumoBinary = checkBinary('sumo-gui')\n",
    "sumoBinary = checkBinary('sumo')\n",
    "roadNetwork = \"./config/osm.sumocfg\"\n",
    "sumoCmd = [sumoBinary, \"-c\", roadNetwork, \"--start\", \"--quit-on-end\"]\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intervehicleConnectivity(threshold = None):\n",
    "    xs = []\n",
    "    ys = []\n",
    "    for vehicle in traci.vehicle.getIDList():\n",
    "        x, y = traci.vehicle.getPosition(vehicle)\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    xs = torch.tensor(xs, dtype=torch.float32).view(-1,1)\n",
    "    ys = torch.tensor(ys, dtype=torch.float32).view(-1,1)\n",
    "    intervehicle_distances = torch.sqrt((xs - xs.t())**2 + (ys - ys.t())**2)\n",
    "    if threshold is not None:\n",
    "        # make the distances 1 if less than the threshold, 0 otherwise\n",
    "        connectivity = torch.where(intervehicle_distances < threshold, torch.ones_like(intervehicle_distances), torch.zeros_like(intervehicle_distances))\n",
    "    return connectivity, xs, ys, intervehicle_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success.\n"
     ]
    }
   ],
   "source": [
    "def randomTrips(dur=1000, density=12):\n",
    "    os.system(\"python $SUMO_HOME/tools/randomTrips.py -n config/osm.net.xml.gz -r config/osm.passenger.trips.xml -e \" + str(dur) + \" -l --insertion-density=\" + str(density))\n",
    "\n",
    "def shouldContinueSim():\n",
    "    numVehicles = traci.simulation.getMinExpectedNumber()\n",
    "    return True if numVehicles > 0 else False\n",
    "\n",
    "def restart(sumoCmd):\n",
    "    with io.StringIO() as buf, redirect_stdout(buf):\n",
    "        try:\n",
    "            traci.close()\n",
    "        except:\n",
    "            pass\n",
    "        traci.start(sumoCmd)\n",
    "\n",
    "def close():\n",
    "    traci.close()\n",
    "\n",
    "randomTrips(800, 1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bfs_distance(adj_matrix):\n",
    "    n_hop_matrix = torch.zeros_like(adj_matrix)\n",
    "    for start_node in range(adj_matrix.size(0)):\n",
    "        visited = [0] * adj_matrix.size(0)\n",
    "        queue = deque([(start_node, 0)])\n",
    "        visited[start_node] = 0\n",
    "        \n",
    "        while queue:\n",
    "            current_node, current_dist = queue.popleft()\n",
    "            \n",
    "            for neighbor, connected in enumerate(adj_matrix[current_node]):\n",
    "                if connected and not visited[neighbor]:\n",
    "                    queue.append((neighbor, current_dist + 1))\n",
    "                    visited[neighbor] = True\n",
    "                    n_hop_matrix[start_node, neighbor] = current_dist + 1\n",
    "    \n",
    "    return n_hop_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RoutingGym(gym.Env):\n",
    "    def __init__(self, sumoCmd, max_steps=1100, n_nodes=57):\n",
    "        self.sumoCmd = sumoCmd\n",
    "        self.step_counter = 0\n",
    "        self.max_steps = max_steps\n",
    "        self.n_nodes = n_nodes\n",
    "        self.vehicle_ids = None\n",
    "        self.start_node = None\n",
    "        self.end_node = None\n",
    "        self.start_x = None\n",
    "        self.start_y = None\n",
    "        self.end_x = None\n",
    "        self.end_y = None\n",
    "        self.xs = None\n",
    "        self.ys = None\n",
    "        self.visited = torch.zeros(n_nodes)\n",
    "        self.distance_to_end = None\n",
    "        self.current_node = None\n",
    "        self.node_features = None\n",
    "        self.adj_matrix = None\n",
    "        self.edge_index = None\n",
    "        self.hop_thresh = None\n",
    "        self.norm_x = None\n",
    "        self.norm_y = None\n",
    "        self.norm_xy = None\n",
    "        self.routing_done = False\n",
    "    \n",
    "    def render(self):\n",
    "        self.show_gui = True\n",
    "\n",
    "    def reset(self):\n",
    "        try:\n",
    "            traci.close()\n",
    "        except:\n",
    "            pass\n",
    "        traci.start(sumoCmd)\n",
    "        self.step_counter = 0\n",
    "\n",
    "        while self.step_counter < 400:\n",
    "            traci.simulationStep()\n",
    "            self.step_counter += 1\n",
    "\n",
    "    def step(self):\n",
    "        traci.simulationStep()\n",
    "        self.routing_done = False\n",
    "        self.step_counter += 1\n",
    "        self.vehicle_ids = traci.vehicle.getIDList()\n",
    "        self.adj_matrix, self.xs, self.ys, inter_vehicle_distance = intervehicleConnectivity(800)\n",
    "        self.edge_index, _ = dense_to_sparse(self.adj_matrix)\n",
    "        self.select_start_end_nodes()\n",
    "        self.distance_to_end = inter_vehicle_distance[self.end_node]\n",
    "        self.distance_to_end = F.pad(self.distance_to_end, (0, 57 - self.distance_to_end.size(0)), \"constant\", 0)\n",
    "        self.visited = torch.zeros_like(self.visited)\n",
    "        current_node_indicators = torch.zeros_like(self.visited)\n",
    "        current_node_indicators[self.current_node] = 1\n",
    "        self.node_features = torch.stack((self.xs, self.ys, self.visited, current_node_indicators, self.distance_to_end)).T\n",
    "        \n",
    "        return self.node_features.to(device)\n",
    "\n",
    "    def select_start_end_nodes(self):\n",
    "        n_hop_matrix = bfs_distance(self.adj_matrix)\n",
    "        self.hop_thresh = min(n_hop_matrix.max(), 5)\n",
    "        starts, ends = torch.where(n_hop_matrix >= self.hop_thresh)\n",
    "        starts = starts.tolist()\n",
    "        ends = ends.tolist()\n",
    "        self.start_node, self.end_node = random.choice(list(zip(starts, ends)))\n",
    "        self.current_node = self.start_node\n",
    "        self.start_x = self.xs[self.start_node].item()\n",
    "        self.start_y = self.ys[self.start_node].item()\n",
    "        self.end_x = self.xs[self.end_node].item()\n",
    "        self.end_y = self.ys[self.end_node].item()\n",
    "        self.norm_x = self.end_x - self.start_x\n",
    "        self.norm_y = self.end_y - self.start_y\n",
    "        self.norm_xy = np.sqrt(self.norm_x**2 + self.norm_y**2)\n",
    "\n",
    "        self.xs = self.xs.squeeze() / self.norm_x\n",
    "        self.ys = self.ys.squeeze() / self.norm_y\n",
    "        # padding with zeros\n",
    "        self.xs = F.pad(self.xs, (0, 57 - self.xs.size(0)), \"constant\", 0)\n",
    "        self.ys = F.pad(self.ys, (0, 57 - self.ys.size(0)), \"constant\", 0)\n",
    "\n",
    "\n",
    "    def act(self, next_hop):\n",
    "        # check if the next hop is reachable\n",
    "        if self.adj_matrix[self.current_node, next_hop] == 1:\n",
    "            self.visited[self.current_node] = 1\n",
    "            self.current_node = next_hop\n",
    "            curr_node_indicators = torch.zeros_like(self.visited)\n",
    "            curr_node_indicators[self.current_node] = 1\n",
    "            self.node_features = torch.stack((self.xs, self.ys, copy.deepcopy(self.visited), curr_node_indicators, self.distance_to_end)).T\n",
    "            reward = self.compute_reward(next_hop)\n",
    "            return self.node_features.to(device), reward.to(device), self.routing_done\n",
    "        else:\n",
    "            return self.node_features.to(device), torch.tensor([[-1]]).to(device), False\n",
    "    \n",
    "    def get_action_mask(self):\n",
    "        action_mask = copy.deepcopy(self.adj_matrix[self.current_node])\n",
    "        action_mask = F.pad(action_mask, (0, self.n_nodes - action_mask.size(0)), \"constant\", 0).to(device)\n",
    "        return action_mask\n",
    "\n",
    "    def get_adj_matrix(self):\n",
    "        return copy.deepcopy(self.adj_matrix).to(device)\n",
    "    \n",
    "    def get_edge_index(self):\n",
    "        return copy.deepcopy(self.edge_index).to(device)\n",
    "        \n",
    "    def compute_reward(self, next_hop):\n",
    "        this_dist_2_end = self.distance_to_end[self.current_node]\n",
    "        next_dist_2_end = self.distance_to_end[next_hop]\n",
    "        reward = (this_dist_2_end - next_dist_2_end) / self.norm_xy\n",
    "        if next_hop == self.end_node:\n",
    "            self.routing_done = True\n",
    "            return reward + self.hop_thresh * 2\n",
    "        else:\n",
    "            return -1 + reward\n",
    "        \n",
    "    def sim_done(self):\n",
    "        \"\"\"\n",
    "        function: get the done state of simulation.\n",
    "        \"\"\"\n",
    "        return not (shouldContinueSim() and self.step_counter <= self.max_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GDQN(nn.Module):\n",
    "    def __init__(self, in_channels=5, n_nodes=57, hidden_dim=32, dropout=0.1):\n",
    "        super(GDQN, self).__init__()\n",
    "        self.convs1 = GCNConv(in_channels, hidden_dim)\n",
    "        self.convs2 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.convs3 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.convs4 = GCNConv(hidden_dim, hidden_dim)\n",
    "        self.convs5 = GCNConv(hidden_dim, 1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(n_nodes, n_nodes)\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, edge_index, action_mask):\n",
    "        x = self.convs1(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.convs2(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.convs3(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.convs4(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = self.convs5(x, edge_index)\n",
    "        x = self.relu(x)\n",
    "        x = x.T\n",
    "        x = self.fc1(x)\n",
    "        x = x * action_mask\n",
    "        x = self.softmax(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "Transition = namedtuple('Transition',\n",
    "                        ('state', 'edge_index', 'action_mask', 'action', 'next_state', 'reward'))\n",
    "\n",
    "\n",
    "class ReplayMemory(object):\n",
    "\n",
    "    def __init__(self, capacity):\n",
    "        self.memory = deque([], maxlen=capacity)\n",
    "\n",
    "    def push(self, *args):\n",
    "        \"\"\"Save a transition\"\"\"\n",
    "        self.memory.append(Transition(*args))\n",
    "\n",
    "    def sample(self, batch_size):\n",
    "        return random.sample(self.memory, batch_size)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.memory)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 128\n",
    "GAMMA = 0.99\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 1000\n",
    "TAU = 0.005\n",
    "LR = 1e-4\n",
    "\n",
    "\n",
    "# Get number of actions from gym action space\n",
    "n_nodes = 57\n",
    "env = RoutingGym(sumoCmd, 1100, n_nodes)\n",
    "# Get the number of state observations\n",
    "\n",
    "policy_net = GDQN().to(device)\n",
    "target_net = GDQN().to(device)\n",
    "target_net.load_state_dict(policy_net.state_dict())\n",
    "\n",
    "optimizer = optim.AdamW(policy_net.parameters(), lr=LR, amsgrad=True)\n",
    "memory = ReplayMemory(1000)\n",
    "\n",
    "\n",
    "steps_done = 0\n",
    "\n",
    "\n",
    "def select_action(node_features, edge_index, action_mask):\n",
    "    global steps_done\n",
    "    sample = random.random()\n",
    "    eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "        math.exp(-1. * steps_done / EPS_DECAY)\n",
    "    steps_done += 1\n",
    "    if sample > eps_threshold:\n",
    "        with torch.no_grad():\n",
    "            # t.max(1) will return the largest column value of each row.\n",
    "            # second column on max result is index of where max element was\n",
    "            # found, so we pick action with the larger expected reward.\n",
    "            return policy_net(node_features, edge_index, action_mask).max(1).indices.view(1, 1)\n",
    "    else:\n",
    "        action_space = torch.where(action_mask == 1)[0]\n",
    "        return torch.tensor([[random.choice(action_space)]], device=device, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_model():\n",
    "    if len(memory) < BATCH_SIZE:\n",
    "        return\n",
    "    transitions = memory.sample(BATCH_SIZE)\n",
    "    # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "    # detailed explanation). This converts batch-array of Transitions\n",
    "    # to Transition of batch-arrays.\n",
    "    batch = Transition(*zip(*transitions))\n",
    "\n",
    "    # Compute a mask of non-final states and concatenate the batch elements\n",
    "    # (a final state would've been the one after which simulation ended)\n",
    "    non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                          batch.next_state)), device=device, dtype=torch.bool)\n",
    "    non_final_next_states = torch.cat([s for s in batch.next_state\n",
    "                                                if s is not None])\n",
    "    state_batch = torch.stack(batch.state)\n",
    "    action_batch = torch.stack(batch.action)\n",
    "    reward_batch = torch.stack(batch.reward)\n",
    "    edge_index_batch = torch.stack(batch.edge_index)\n",
    "    action_mask_batch = torch.stack(batch.action_mask)\n",
    "  \n",
    "\n",
    "    # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "    # columns of actions taken. These are the actions which would've been taken\n",
    "    # for each batch state according to policy_net\n",
    "    print(state_batch.shape, edge_index_batch.shape, action_mask_batch.shape)\n",
    "    state_action_values = policy_net(state_batch, edge_index_batch, action_mask_batch).gather(1, action_batch)\n",
    "\n",
    "    # Compute V(s_{t+1}) for all next states.\n",
    "    # Expected values of actions for non_final_next_states are computed based\n",
    "    # on the \"older\" target_net; selecting their best reward with max(1).values\n",
    "    # This is merged based on the mask, such that we'll have either the expected\n",
    "    # state value or 0 in case the state was final.\n",
    "    next_state_values = torch.zeros(BATCH_SIZE, device=device)\n",
    "    with torch.no_grad():\n",
    "        next_state_values[non_final_mask] = target_net(non_final_next_states).max(1).values\n",
    "    # Compute the expected Q values\n",
    "    expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "    # Compute Huber loss\n",
    "    criterion = nn.SmoothL1Loss()\n",
    "    loss = criterion(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "    # Optimize the model\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    # In-place gradient clipping\n",
    "    torch.nn.utils.clip_grad_value_(policy_net.parameters(), 100)\n",
    "    optimizer.step()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Simulation ended at time: 401.00\n",
      "Reason: TraCI requested termination.\n",
      "Performance: \n",
      " Duration: 157.26s\n",
      " TraCI-Duration: 0.01s\n",
      " Real time factor: 2.5499\n",
      " UPS: 54.177450\n",
      "Vehicles: \n",
      " Inserted: 45 (Loaded: 48)\n",
      " Running: 39\n",
      " Waiting: 0\n",
      "Statistics (avg of 6):\n",
      " RouteLength: 1965.69\n",
      " Speed: 10.02\n",
      " Duration: 203.50\n",
      " WaitingTime: 1.83\n",
      " TimeLoss: 23.67\n",
      " DepartDelay: 0.35\n",
      "\n",
      " Retrying in 1 seconds\n",
      "***Starting server on port 46305 ***\n",
      "Loading net-file from './config/osm.net.xml.gz' ... done (109ms).\n",
      "Loading done.\n",
      "Simulation version 1.20.0 started with time: 0.00.\n",
      "torch.Size([128, 57, 5]) torch.Size([128, 2, 143]) torch.Size([128, 57])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Sizes of tensors must match except in dimension 1. Expected size 128 but got size 2 for tensor number 1 in the list.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[305], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Perform one step of the optimization (on the policy network)\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m \u001b[43moptimize_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Soft update of the target network's weights\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# θ′ ← τ θ + (1 −τ )θ′\u001b[39;00m\n\u001b[1;32m     31\u001b[0m target_net_state_dict \u001b[38;5;241m=\u001b[39m target_net\u001b[38;5;241m.\u001b[39mstate_dict()\n",
      "Cell \u001b[0;32mIn[304], line 27\u001b[0m, in \u001b[0;36moptimize_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;66;03m# Compute Q(s_t, a) - the model computes Q(s_t), then we select the\u001b[39;00m\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# columns of actions taken. These are the actions which would've been taken\u001b[39;00m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# for each batch state according to policy_net\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(state_batch\u001b[38;5;241m.\u001b[39mshape, edge_index_batch\u001b[38;5;241m.\u001b[39mshape, action_mask_batch\u001b[38;5;241m.\u001b[39mshape)\n\u001b[0;32m---> 27\u001b[0m state_action_values \u001b[38;5;241m=\u001b[39m \u001b[43mpolicy_net\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_mask_batch\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgather(\u001b[38;5;241m1\u001b[39m, action_batch)\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Compute V(s_{t+1}) for all next states.\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# Expected values of actions for non_final_next_states are computed based\u001b[39;00m\n\u001b[1;32m     31\u001b[0m \u001b[38;5;66;03m# on the \"older\" target_net; selecting their best reward with max(1).values\u001b[39;00m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# This is merged based on the mask, such that we'll have either the expected\u001b[39;00m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# state value or 0 in case the state was final.\u001b[39;00m\n\u001b[1;32m     34\u001b[0m next_state_values \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(BATCH_SIZE, device\u001b[38;5;241m=\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/sumo/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sumo/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[302], line 15\u001b[0m, in \u001b[0;36mGDQN.forward\u001b[0;34m(self, x, edge_index, action_mask)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, edge_index, action_mask):\n\u001b[0;32m---> 15\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvs1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     16\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(x)\n\u001b[1;32m     17\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout(x)\n",
      "File \u001b[0;32m~/miniconda3/envs/sumo/lib/python3.10/site-packages/torch/nn/modules/module.py:1532\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1530\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1531\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1532\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/sumo/lib/python3.10/site-packages/torch/nn/modules/module.py:1541\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1537\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1539\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1540\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1541\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1543\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1544\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/sumo/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:241\u001b[0m, in \u001b[0;36mGCNConv.forward\u001b[0;34m(self, x, edge_index, edge_weight)\u001b[0m\n\u001b[1;32m    239\u001b[0m cache \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index\n\u001b[1;32m    240\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m cache \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 241\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43mgcn_norm\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# yapf: disable\u001b[39;49;00m\n\u001b[1;32m    242\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnode_dim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    243\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimproved\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_self_loops\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    244\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcached:\n\u001b[1;32m    245\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cached_edge_index \u001b[38;5;241m=\u001b[39m (edge_index, edge_weight)\n",
      "File \u001b[0;32m~/miniconda3/envs/sumo/lib/python3.10/site-packages/torch_geometric/nn/conv/gcn_conv.py:99\u001b[0m, in \u001b[0;36mgcn_norm\u001b[0;34m(edge_index, edge_weight, num_nodes, improved, add_self_loops, flow, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m num_nodes \u001b[38;5;241m=\u001b[39m maybe_num_nodes(edge_index, num_nodes)\n\u001b[1;32m     98\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m add_self_loops:\n\u001b[0;32m---> 99\u001b[0m     edge_index, edge_weight \u001b[38;5;241m=\u001b[39m \u001b[43madd_remaining_self_loops\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    100\u001b[0m \u001b[43m        \u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43medge_weight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfill_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_nodes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    102\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m edge_weight \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    103\u001b[0m     edge_weight \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mones((edge_index\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m), ), dtype\u001b[38;5;241m=\u001b[39mdtype,\n\u001b[1;32m    104\u001b[0m                              device\u001b[38;5;241m=\u001b[39medge_index\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/miniconda3/envs/sumo/lib/python3.10/site-packages/torch_geometric/utils/loop.py:654\u001b[0m, in \u001b[0;36madd_remaining_self_loops\u001b[0;34m(edge_index, edge_attr, fill_value, num_nodes)\u001b[0m\n\u001b[1;32m    651\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mjit\u001b[38;5;241m.\u001b[39mis_scripting() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(edge_index, EdgeIndex):\n\u001b[1;32m    652\u001b[0m     edge_index\u001b[38;5;241m.\u001b[39m_is_undirected \u001b[38;5;241m=\u001b[39m is_undirected\n\u001b[0;32m--> 654\u001b[0m edge_index \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43medge_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloop_index\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m edge_index, edge_attr\n",
      "File \u001b[0;32m~/miniconda3/envs/sumo/lib/python3.10/site-packages/torch_geometric/edge_index.py:1057\u001b[0m, in \u001b[0;36mEdgeIndex.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m \u001b[38;5;129m@classmethod\u001b[39m\n\u001b[1;32m   1038\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__torch_function__\u001b[39m(\n\u001b[1;32m   1039\u001b[0m     \u001b[38;5;28mcls\u001b[39m: Type,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1054\u001b[0m     \u001b[38;5;66;03m# To account for this, we hold a number of `HANDLED_FUNCTIONS` that\u001b[39;00m\n\u001b[1;32m   1055\u001b[0m     \u001b[38;5;66;03m# implement specific functions for valid `EdgeIndex` routines.\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m HANDLED_FUNCTIONS:\n\u001b[0;32m-> 1057\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mHANDLED_FUNCTIONS\u001b[49m\u001b[43m[\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1059\u001b[0m     \u001b[38;5;66;03m# For all other PyTorch functions, we return a vanilla PyTorch tensor.\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m     _types \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mtuple\u001b[39m(Tensor \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(t, \u001b[38;5;28mcls\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m t \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m types)\n",
      "File \u001b[0;32m~/miniconda3/envs/sumo/lib/python3.10/site-packages/torch_geometric/edge_index.py:1204\u001b[0m, in \u001b[0;36mcat\u001b[0;34m(tensors, dim, out)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tensors) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   1202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensors[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1204\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43mTensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__torch_function__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1205\u001b[0m \u001b[43m                                   \u001b[49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1207\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m dim \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:  \u001b[38;5;66;03m# No valid `EdgeIndex` anymore.\u001b[39;00m\n\u001b[1;32m   1208\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output\n",
      "File \u001b[0;32m~/miniconda3/envs/sumo/lib/python3.10/site-packages/torch/_tensor.py:1443\u001b[0m, in \u001b[0;36mTensor.__torch_function__\u001b[0;34m(cls, func, types, args, kwargs)\u001b[0m\n\u001b[1;32m   1440\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m   1442\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _C\u001b[38;5;241m.\u001b[39mDisableTorchFunctionSubclass():\n\u001b[0;32m-> 1443\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1444\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01min\u001b[39;00m get_default_nowrap_functions():\n\u001b[1;32m   1445\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m ret\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Sizes of tensors must match except in dimension 1. Expected size 128 but got size 2 for tensor number 1 in the list."
     ]
    }
   ],
   "source": [
    "# Initialize the environment and get its state\n",
    "env.reset()\n",
    "done = False\n",
    "while not done:\n",
    "    done = env.sim_done()\n",
    "    state = env.step()\n",
    "    edge_index = env.get_edge_index()\n",
    "    routing_done = False\n",
    "    while not routing_done:\n",
    "        action_mask = env.get_action_mask()\n",
    "        action = select_action(state, edge_index, action_mask)\n",
    "        node_features, reward, routing_done = env.act(action.item())\n",
    "        reward = torch.tensor([reward], device=device)\n",
    "\n",
    "        if routing_done:\n",
    "            next_state = None\n",
    "        else:\n",
    "            next_state = node_features\n",
    "\n",
    "        # Store the transition in memory\n",
    "        memory.push(state, edge_index, action_mask, action, next_state, reward)\n",
    "\n",
    "        # Move to the next state\n",
    "        state = next_state\n",
    "\n",
    "        # Perform one step of the optimization (on the policy network)\n",
    "        optimize_model()\n",
    "\n",
    "        # Soft update of the target network's weights\n",
    "        # θ′ ← τ θ + (1 −τ )θ′\n",
    "        target_net_state_dict = target_net.state_dict()\n",
    "        policy_net_state_dict = policy_net.state_dict()\n",
    "        for key in policy_net_state_dict:\n",
    "            target_net_state_dict[key] = policy_net_state_dict[key]*TAU + target_net_state_dict[key]*(1-TAU)\n",
    "        target_net.load_state_dict(target_net_state_dict)\n",
    "\n",
    "print('Complete')\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3355, -0.9334],\n",
      "        [-0.4502, -1.1951],\n",
      "        [-0.5298, -1.3113],\n",
      "        [-0.5541, -1.3516],\n",
      "        [-0.6733, -1.5651],\n",
      "        [-0.6088, -1.3865],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015]], grad_fn=<AddBackward0>)\n",
      "tensor([[-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015],\n",
      "        [-0.3666, -0.9978],\n",
      "        [-0.5948, -1.4612],\n",
      "        [-0.6101, -1.4015]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch_geometric.data import Data, DataLoader\n",
    "from torch_geometric.nn import GCNConv\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Step 1: Prepare individual graph data objects\n",
    "graphs = []\n",
    "for i in range(128):  # Assuming we have 128 graphs\n",
    "    # Example edge index and node features for each graph\n",
    "    edge_index = torch.tensor([[0, 1, 1, 2],\n",
    "                               [1, 0, 2, 1]], dtype=torch.long)\n",
    "    if i == 1:\n",
    "        edge_index = torch.tensor([[0, 1, 1, 2, 2, 3],\n",
    "                                   [1, 0, 2, 1, 3, 2]], dtype=torch.long)\n",
    "    elif i == 2:\n",
    "        edge_index = torch.tensor([[0],\n",
    "                               [1]], dtype=torch.long)\n",
    "    x = torch.tensor([[1, 2],\n",
    "                      [3, 4],\n",
    "                      [5, 6]], dtype=torch.float)\n",
    "    \n",
    "    # Create a Data object for each graph\n",
    "    data = Data(x=x, edge_index=edge_index)\n",
    "    graphs.append(data)\n",
    "\n",
    "# Step 2: Create a DataLoader for batching\n",
    "loader = DataLoader(graphs, batch_size=32, shuffle=True)  # Adjust batch_size as needed\n",
    "\n",
    "# Step 3: Define a simple GCN model for demonstration\n",
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = GCNConv(in_channels=2, out_channels=16)\n",
    "        self.conv2 = GCNConv(in_channels=16, out_channels=2)\n",
    "\n",
    "    def forward(self, data):\n",
    "        x, edge_index = data.x, data.edge_index\n",
    "        x = self.conv1(x, edge_index)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x, edge_index)\n",
    "        return x\n",
    "\n",
    "# Instantiate the model\n",
    "model = GCN()\n",
    "\n",
    "# Step 4: Iterate over the DataLoader and pass batches through the model\n",
    "for batch in loader:\n",
    "    out = model(batch)\n",
    "    print(out)\n",
    "    # You can now perform loss computation, backpropagation, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
