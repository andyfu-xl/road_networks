{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SUMO_HOME found\n",
      "SUMO_HOME found\n",
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import traci\n",
    "from sumolib import checkBinary\n",
    "import torch\n",
    "import sys\n",
    "import os\n",
    "from utils import *\n",
    "import copy\n",
    "import gym\n",
    "import random\n",
    "from Models import GRUModel\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.utils import dense_to_sparse\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import math\n",
    "\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    print('SUMO_HOME found')\n",
    "    sys.path.append(os.path.join(os.environ['SUMO_HOME'], 'tools'))\n",
    "\n",
    "# sumoBinary = checkBinary('sumo-gui')\n",
    "sumoBinary = checkBinary('sumo')\n",
    "roadNetwork = \"./config/osm.sumocfg\"\n",
    "sumoCmd = [sumoBinary, \"-c\", roadNetwork, \"--start\", \"--quit-on-end\"]\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Knowledges:\n",
    "    def __init__(self):\n",
    "        self.knowledges = {}\n",
    "        self.delays = {}\n",
    "    \n",
    "    def add_observations(self, vehicles, observed_vehicles):\n",
    "        for vehicle, visibility in zip(vehicles, observed_vehicles):\n",
    "            if vehicle not in self.knowledges:\n",
    "                self.knowledges[vehicle] = []\n",
    "                self.delays[vehicle] = 0\n",
    "            self.knowledges[vehicle].append(int(visibility))\n",
    "            if visibility == 0:\n",
    "                self.delays[vehicle] += 1\n",
    "            else:\n",
    "                self.delays[vehicle] = 0\n",
    "    \n",
    "    def merge_knowledges(self, new_knowledges, new_delays):\n",
    "        prev_missing, prev_delay, _, _ = self.evaluate_knowledge()\n",
    "        for vehicle, visibility in new_knowledges.items():\n",
    "            if vehicle not in self.knowledges:\n",
    "                self.knowledges[vehicle] = copy.deepcopy(visibility)\n",
    "                self.delays[vehicle] = new_delays[vehicle]\n",
    "            else:\n",
    "                for i in range(1, len(self.knowledges[vehicle])+1):\n",
    "                    if i > len(visibility):\n",
    "                        break\n",
    "                    self.knowledges[vehicle][-i] = visibility[-i] | self.knowledges[vehicle][-i]\n",
    "                self.delays[vehicle] = min(self.delays[vehicle], new_delays[vehicle])\n",
    "        new_missing, new_delay, _, _ = self.evaluate_knowledge()\n",
    "        return copy.deepcopy(self.knowledges), copy.deepcopy(self.delays), prev_missing - new_missing, prev_delay - new_delay\n",
    "\n",
    "    def get_knowledges(self):\n",
    "        return copy.deepcopy(self.knowledges)\n",
    "    \n",
    "    def get_delays(self):\n",
    "        return copy.deepcopy(self.delays)\n",
    "    \n",
    "    def evaluate_knowledge(self, large_delay_threshold=10):\n",
    "        observed = 0\n",
    "        delay = 0\n",
    "        large_delay = 0\n",
    "        num_vehicles = len(self.knowledges)\n",
    "        whole_missing = 0\n",
    "        total = 0\n",
    "        for vehicle, visibility in self.knowledges.items():\n",
    "            observed += sum(visibility) \n",
    "            total += len(visibility)\n",
    "            delay += self.delays[vehicle]\n",
    "            if self.delays[vehicle] >= large_delay_threshold or sum(visibility) <= 3:\n",
    "                large_delay += 1\n",
    "            if sum(visibility) == 0:\n",
    "                whole_missing += len(visibility)\n",
    "        return 1-(observed / total), delay / num_vehicles, large_delay / num_vehicles, whole_missing / total\n",
    "\n",
    "class Vehicle:\n",
    "    def __init__(self):\n",
    "        self.sent = {}\n",
    "        self.received = 0\n",
    "\n",
    "    def step(self):\n",
    "        self.received = 0\n",
    "        for vehicle, lag in self.sent.items():\n",
    "            self.sent[vehicle] += 1\n",
    "        self.sent = {vehicle: lag for vehicle, lag in self.sent.items() if lag < 10}\n",
    "    \n",
    "    def receive(self):\n",
    "        self.received += 1\n",
    "\n",
    "    # lag: the time since the last communication with a neighbor\n",
    "    def select(self, neighbors):\n",
    "        max_lag = 0\n",
    "        selected = None\n",
    "        for neighbor in neighbors:\n",
    "            if neighbor not in self.sent:\n",
    "                selected = neighbor\n",
    "                break\n",
    "            if self.sent[neighbor] > max_lag:\n",
    "                max_lag = self.sent[neighbor]\n",
    "                selected = neighbor\n",
    "        return selected\n",
    "    \n",
    "    def send(self, selected_neighbor):\n",
    "        self.sent[selected_neighbor] = 0\n",
    "\n",
    "def connectivity(xs,ys, threshold=800):\n",
    "    xs = torch.tensor(xs, dtype=torch.float32).view(-1,1)\n",
    "    ys = torch.tensor(ys, dtype=torch.float32).view(-1,1)\n",
    "    intervehicle_distances = torch.sqrt((xs - xs.t())**2 + (ys - ys.t())**2)\n",
    "    if threshold is not None:\n",
    "        # make the distances 1 if less than the threshold, 0 otherwise\n",
    "        connectivity = torch.where(intervehicle_distances < threshold, torch.ones_like(intervehicle_distances), torch.zeros_like(intervehicle_distances))\n",
    "    connectivity = connectivity - torch.diag(torch.diag(connectivity))\n",
    "    return connectivity, xs, ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Incomplete_Routing_Gym(gym.Env):\n",
    "    def __init__(self, sumoCmd, model, max_steps=1100, n_nodes=57, max_routing_steps=30, max_n_neighbors=6):\n",
    "        self.sumoCmd = sumoCmd\n",
    "        self.step_counter = 0\n",
    "        self.max_steps = max_steps\n",
    "        self.n_nodes = n_nodes\n",
    "        self.start_node = None\n",
    "        self.end_node = None\n",
    "        self.current_node = None\n",
    "        self.node_features = None\n",
    "        self.adj_matrix = None\n",
    "        self.edge_index = None\n",
    "        self.hop_thresh = None\n",
    "        self.routing_done = False\n",
    "        self.routing_steps = 0\n",
    "        self.min_n_hops = None\n",
    "        self.end_node_indicator = torch.zeros(n_nodes)\n",
    "        self.max_routing_steps = max_routing_steps\n",
    "        self.n_hop_matrix = None\n",
    "        self.neighbors_indicator = None\n",
    "        self.action_space = None\n",
    "        self.to_remove_indices = None\n",
    "        self.prunned_adj_matrix = None\n",
    "        self.prunned_n_hop_matrix = None\n",
    "        self.state = None\n",
    "        self.max_n_neighbors = max_n_neighbors\n",
    "        self.ids = None\n",
    "        self.vehicle_knowledges = {}\n",
    "        self.vehicle_records = {}\n",
    "        self.GRUModel = model\n",
    "        self.GRUModel.eval()\n",
    "\n",
    "        self.cached_states = {}\n",
    "\n",
    "        self.xs = None\n",
    "        self.ys = None\n",
    "        self.start_x = None\n",
    "        self.start_y = None\n",
    "        self.end_x = None\n",
    "        self.end_y = None\n",
    "\n",
    "        self.total_missing_ratio = 0\n",
    "        self.total_error = 0\n",
    "        self.total_num_graphs = 0\n",
    "\n",
    "        self.delay_distribution = []\n",
    "\n",
    "        self.observed_adj_matrix = None\n",
    "        self.observed_n_hop_matrix = None\n",
    "\n",
    "        self.trajectory_dict = {}\n",
    "\n",
    "\n",
    "        self.load_all_trajectory()\n",
    "\n",
    "    \n",
    "\n",
    "    def load_all_trajectory(self):\n",
    "        self.checkpoints_dict = get_planned_path()\n",
    "        checkpoints = list(self.checkpoints_dict.values())\n",
    "        checkpoints = torch.tensor(checkpoints).float() / 10\n",
    "        position_df = pd.read_csv('trajectory_time.csv')\n",
    "        position_df.set_index('Unnamed: 0', inplace=True)\n",
    "        position_array = position_df.to_numpy()\n",
    "        sequence_length = position_df.shape[1] // 2\n",
    "        tensor_list = []\n",
    "\n",
    "        for row in position_array:\n",
    "            reshaped_tensor = torch.tensor(row.reshape(sequence_length, 2))\n",
    "            tensor_list.append(reshaped_tensor)\n",
    "\n",
    "        all_trajectories_tensor = torch.stack(tensor_list).float() / 10\n",
    "\n",
    "        next_checkpoint = torch.zeros_like(all_trajectories_tensor)\n",
    "        next_next_checkpoint = torch.zeros_like(all_trajectories_tensor)\n",
    "        checkpoints_pad_1 = F.pad(checkpoints, (0, 0, 1, 0))\n",
    "        for i in range(all_trajectories_tensor.shape[1]):\n",
    "            _, min_indices = project_to_nearest(all_trajectories_tensor[:, i], checkpoints)\n",
    "            next_checkpoint[:, i] = checkpoints_pad_1[range(checkpoints.shape[0]), min_indices+1]\n",
    "            next_next_checkpoint[:, i] = checkpoints_pad_1[range(checkpoints.shape[0]), min_indices+2]\n",
    "\n",
    "        all_trajectories_tensor = torch.cat((all_trajectories_tensor, next_checkpoint, next_next_checkpoint), dim=2)\n",
    "\n",
    "        # convert all_trajectories_tensor to a dictionary, where keys are the vehicle ids\n",
    "        for i, n in enumerate(position_df.index):\n",
    "            self.trajectory_dict[str(n)] = all_trajectories_tensor[i]\n",
    "            self.checkpoints_dict[str(n)] = checkpoints[i]\n",
    "\n",
    "    def reset(self):\n",
    "        try:\n",
    "            traci.close()\n",
    "        except:\n",
    "            pass\n",
    "        traci.start(self.sumoCmd)\n",
    "        self.step_counter = traci.simulation.getTime()\n",
    "\n",
    "        while self.step_counter < 400:\n",
    "            self.simstep_with_sync()\n",
    "\n",
    "\n",
    "    def node_pruning(self):\n",
    "        self.prunned_adj_matrix = copy.deepcopy(self.observed_adj_matrix)\n",
    "        self.prunned_n_hop_matrix = copy.deepcopy(self.observed_n_hop_matrix)\n",
    "        neighbor_indices = np.where(self.observed_adj_matrix[self.current_node] == 1)[0]\n",
    "        if len(neighbor_indices) >= self.max_n_neighbors:\n",
    "            two_hop_neighbours_indices = np.where(self.observed_n_hop_matrix[self.current_node] == 2)[0]\n",
    "            two_hop_neighbours_mask = (self.observed_n_hop_matrix[self.current_node] == 2).type(torch.int)\n",
    "            # direct neighbours connectivities with two hop neighbours\n",
    "            neighbour_dict = {}\n",
    "            for neighbour_index in neighbor_indices:\n",
    "                neighbour_dict[neighbour_index] = two_hop_neighbours_indices[np.where(self.observed_adj_matrix[neighbour_index][two_hop_neighbours_indices] == 1)[0]]\n",
    "            # sort by the number of two hop neighbours\n",
    "            neighbour_dict = dict(sorted(neighbour_dict.items(), key=lambda item: len(item[1]), reverse=True))\n",
    "\n",
    "            self.to_remove_indices = []\n",
    "            action_space = 0\n",
    "            for neighbour_index, two_hop_neighbours_indices in neighbour_dict.items():\n",
    "                mask_sum_before = torch.sum(two_hop_neighbours_mask)\n",
    "                two_hop_neighbours_mask[two_hop_neighbours_indices] = 0\n",
    "                mask_sum_after = torch.sum(two_hop_neighbours_mask)\n",
    "                if mask_sum_after < mask_sum_before:\n",
    "                    action_space += 1\n",
    "                else:\n",
    "                    self.to_remove_indices.append(neighbour_index)\n",
    "            if action_space < self.max_n_neighbors:\n",
    "                self.to_remove_indices = random.sample(self.to_remove_indices, len(self.to_remove_indices) - (self.max_n_neighbors - action_space))\n",
    "            self.prunned_adj_matrix[self.to_remove_indices, :] = 0\n",
    "            self.prunned_adj_matrix[:, self.to_remove_indices] = 0\n",
    "            self.prunned_n_hop_matrix[self.to_remove_indices, :] = -100\n",
    "            self.prunned_n_hop_matrix[:, self.to_remove_indices] = -100\n",
    "        self.prunned_n_hop_matrix = self.prunned_n_hop_matrix - torch.diag(torch.diag(self.prunned_n_hop_matrix))\n",
    "        self.prunned_adj_matrix = self.prunned_adj_matrix - torch.diag(torch.diag(self.prunned_adj_matrix))\n",
    "\n",
    "\n",
    "    def next_episode(self, refresh=False):\n",
    "        self.routing_done = False\n",
    "        self.routing_steps = 0\n",
    "        if not refresh:\n",
    "            self.simstep_with_sync()\n",
    "            self.adj_matrix = F.pad(self.adj_matrix, (0, self.n_nodes - self.adj_matrix.size(0), \n",
    "                                                  0, self.n_nodes - self.adj_matrix.size(1)), \"constant\", 0)\n",
    "            self.n_hop_matrix = F.pad(self.n_hop_matrix, (0, self.n_nodes - self.n_hop_matrix.size(0), \n",
    "                                                      0, self.n_nodes - self.n_hop_matrix.size(1)), \"constant\", -100)\n",
    "        self.select_start_end_nodes()\n",
    "        self.current_node = self.start_node\n",
    "        self.get_state()\n",
    "        return copy.deepcopy(self.state)\n",
    "\n",
    "    def simstep_with_sync(self):\n",
    "        traci.simulationStep()\n",
    "        self.cached_states = {}\n",
    "        self.step_counter = int(traci.simulation.getTime())\n",
    "        self.adj_matrix, self.xs, self.ys = intervehicleConnectivity_xs_ys(800)\n",
    "        self.n_hop_matrix = bfs_distance(self.adj_matrix)\n",
    "        self.ids = traci.vehicle.getIDList()\n",
    "        action_spaces = self.adj_matrix - torch.diag(torch.diag(self.adj_matrix))\n",
    "\n",
    "        for i, vehicle in enumerate(self.ids):\n",
    "            if vehicle not in self.vehicle_knowledges:\n",
    "                self.vehicle_knowledges[vehicle] = Knowledges()\n",
    "            if vehicle not in self.vehicle_records:\n",
    "                self.vehicle_records[vehicle] = Vehicle()\n",
    "            self.vehicle_knowledges[vehicle].add_observations(self.ids, self.adj_matrix[i])\n",
    "        \n",
    "        for i, vehicle in enumerate(self.ids):\n",
    "            non_zero_indices = torch.where(action_spaces[i] == 1)[0]\n",
    "            neighbors = [self.ids[j] for j in non_zero_indices] \n",
    "            if len(neighbors) > 0:\n",
    "                select_neighbour = self.vehicle_records[vehicle].select(neighbors)\n",
    "                if select_neighbour is None:\n",
    "                    continue\n",
    "                self.vehicle_records[vehicle].send(select_neighbour)\n",
    "                self.vehicle_knowledges[select_neighbour].merge_knowledges(self.vehicle_knowledges[vehicle].get_knowledges(), self.vehicle_knowledges[vehicle].get_delays())\n",
    "\n",
    "                self.vehicle_records[select_neighbour].send(vehicle)\n",
    "                self.vehicle_knowledges[vehicle].merge_knowledges(self.vehicle_knowledges[select_neighbour].get_knowledges(), self.vehicle_knowledges[select_neighbour].get_delays())\n",
    "            \n",
    "        for vehicle in self.vehicle_records.values():\n",
    "            vehicle.step()\n",
    "\n",
    "        \n",
    "    def select_start_end_nodes(self):\n",
    "        self.hop_thresh = min(self.n_hop_matrix.max(), 5)\n",
    "        starts, ends = torch.where(self.hop_thresh == self.n_hop_matrix)\n",
    "        starts = starts.tolist()\n",
    "        ends = ends.tolist()\n",
    "        self.start_node, self.end_node = random.choice(list(zip(starts, ends)))\n",
    "        # minimal number of hops between start and end nodes\n",
    "        self.min_n_hops = self.n_hop_matrix[self.start_node, self.end_node]\n",
    "\n",
    "        self.start_x = self.xs[self.start_node]\n",
    "        self.start_y = self.ys[self.start_node]\n",
    "        self.end_x = self.xs[self.end_node]\n",
    "        self.end_y = self.ys[self.end_node]\n",
    "\n",
    "    \n",
    "    def get_state(self):\n",
    "        if self.current_node in self.cached_states:\n",
    "            self.state = copy.deepcopy(self.cached_states[self.current_node])\n",
    "        self.compute_state()\n",
    "        self.cached_states[self.current_node] = copy.deepcopy(self.state)\n",
    "    \n",
    "\n",
    "    def compute_state(self):\n",
    "        current_vehicle_knowledge = self.vehicle_knowledges[self.ids[self.current_node]].get_knowledges()\n",
    "        current_vehicle_delay = self.vehicle_knowledges[self.ids[self.current_node]].get_delays()\n",
    "        observed_vehicle_xs = []\n",
    "        observed_vehicle_ys = []\n",
    "        for vehicle in self.ids:\n",
    "            if current_vehicle_delay[vehicle] == 0:\n",
    "                observed_vehicle_xs.append(self.xs[self.ids.index(vehicle)])\n",
    "                observed_vehicle_ys.append(self.ys[self.ids.index(vehicle)])\n",
    "            elif current_vehicle_delay[vehicle] >= 10 or sum(current_vehicle_knowledge[vehicle]) <= 3:\n",
    "                observed_vehicle_xs.append(0)\n",
    "                observed_vehicle_ys.append(0)\n",
    "            else:\n",
    "                x, y = self.estimate_vehicle_positions(vehicle, current_vehicle_knowledge[vehicle], current_vehicle_delay[vehicle])\n",
    "                observed_vehicle_xs.append(x)\n",
    "                observed_vehicle_ys.append(y)\n",
    "        \n",
    "        self.observed_adj_matrix, xs, ys = connectivity(observed_vehicle_xs, observed_vehicle_ys)\n",
    "        # set connectivity to 0 if the vehicle is not observed\n",
    "        not_observed_indices = torch.where(xs == -1)[0]\n",
    "        self.observed_adj_matrix[not_observed_indices, :] = 0\n",
    "        self.observed_adj_matrix[:, not_observed_indices] = 0\n",
    "\n",
    "        self.observed_adj_matrix = F.pad(self.observed_adj_matrix, (0, self.n_nodes - self.observed_adj_matrix.size(0), \n",
    "                                                  0, self.n_nodes - self.observed_adj_matrix.size(1)), \"constant\", 0)\n",
    "        # set the neighbouring connectivity to the true connectivity\n",
    "        non_neighbour_indices = torch.where(self.adj_matrix[self.current_node] == 0)[0]\n",
    "        self.observed_adj_matrix[self.current_node, non_neighbour_indices] = 0\n",
    "        self.observed_adj_matrix[non_neighbour_indices, self.current_node] = 0\n",
    "\n",
    "        norm_xs = (xs - self.end_x) / (self.start_x - self.end_x)\n",
    "        norm_ys = (ys - self.end_y) / (self.start_y - self.end_y)\n",
    "        # set the norm_xs and norm_ys to 0 if the vehicle is not observed\n",
    "        norm_xs[not_observed_indices] = 0\n",
    "        norm_ys[not_observed_indices] = 0\n",
    "        # padding the matrices to the same size\n",
    "        norm_xs = F.pad(norm_xs, (0, 0, 0, self.n_nodes - norm_xs.size(0)), \"constant\", 0)\n",
    "        norm_ys = F.pad(norm_ys, (0, 0, 0, self.n_nodes - norm_ys.size(0)), \"constant\", 0)\n",
    "        self.observed_n_hop_matrix = bfs_distance(self.observed_adj_matrix)\n",
    "        self.node_pruning()\n",
    "        edge_index = dense_to_sparse(self.prunned_adj_matrix)[0]\n",
    "\n",
    "        curr_node_indicator = torch.zeros(self.n_nodes)\n",
    "        curr_node_indicator[self.current_node] = 1\n",
    "        distances = self.prunned_n_hop_matrix[self.end_node]\n",
    "        distances[distances == -100] = 8\n",
    "        distances[distances > 7] = 7\n",
    "        one_hot_distances = F.one_hot(distances.long(), num_classes=8).type(torch.float32)\n",
    "        neighbour_indicator = self.prunned_adj_matrix[self.current_node]\n",
    "        node_features = torch.cat((one_hot_distances, self.end_node_indicator.unsqueeze(1), \n",
    "                                   curr_node_indicator.unsqueeze(1), neighbour_indicator.unsqueeze(1), \n",
    "                                   norm_xs, norm_ys), dim=1).to(device)\n",
    "        self.state = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "\n",
    "    def act(self, neighbor_index):\n",
    "        self.routing_steps += 1\n",
    "        neighbors = torch.where(self.prunned_adj_matrix[self.current_node] == 1)[0]\n",
    "        valid_action_size = len(neighbors)\n",
    "        if valid_action_size <= neighbor_index:\n",
    "            self.routing_done = self.routing_steps >= self.max_routing_steps\n",
    "            if self.routing_done:\n",
    "                return self.state, torch.tensor(-1).to(device), self.routing_done\n",
    "            return self.state, torch.tensor(-0.15).to(device), self.routing_done\n",
    "        else:\n",
    "            next_hop = neighbors[neighbor_index]\n",
    "            reward = self.compute_reward(next_hop)\n",
    "            self.current_node = next_hop\n",
    "            self.get_state()\n",
    "            return self.state, torch.tensor(reward).to(device), self.routing_done\n",
    "\n",
    "    \n",
    "    def estimate_vehicle_positions(self, vehicle, observation_history, delay):\n",
    "        last_seen_time = int(self.step_counter - delay)\n",
    "        first_one_index = int(observation_history.index(1))\n",
    "        sequence_length = min(len(observation_history) - first_one_index, 20)\n",
    "        # these last seen value will be used to calibrate the position of the vehicle\n",
    "        # we set the last seen value to 50, 50, as the autoregressive model is trained on the normalized values\n",
    "        last_seen_x = self.trajectory_dict[vehicle][last_seen_time][0].item()\n",
    "        last_seen_y = self.trajectory_dict[vehicle][last_seen_time][1].item()\n",
    "        modif = (torch.tensor([last_seen_x, last_seen_y])-torch.tensor([50, 50])).repeat(1, 3)\n",
    "\n",
    "        masks = torch.tensor(observation_history).unsqueeze(0).unsqueeze(2).repeat(1, 1, 6)\n",
    "\n",
    "        paths = self.checkpoints_dict[vehicle].unsqueeze(0)\n",
    "        inputs = copy.deepcopy(self.trajectory_dict[vehicle][self.step_counter-sequence_length+1:self.step_counter+1].unsqueeze(0))\n",
    "        inputs -= modif\n",
    "        masks = masks[:, -sequence_length:, :]\n",
    "        modified_x, modified_y = self.GRU_inference(inputs.to(device), masks.to(device), paths.to(device))\n",
    "        x, y = (modified_x + modif[0][0]).item() * 10, (modified_y + modif[0][1]).item() * 10\n",
    "        return x, y\n",
    "    \n",
    "\n",
    "    def GRU_inference(self, inputs, masks, paths):\n",
    "        with torch.no_grad():\n",
    "            hidden = None\n",
    "            seq_len = inputs.size(1)\n",
    "            current_input = inputs[:, 0, :].unsqueeze(1)\n",
    "            for t in range(1, seq_len):\n",
    "                prediction, hidden = self.GRUModel(current_input, hidden)\n",
    "                projection_with_checkpoints = project_to_nearest_with_checkpoints(prediction, paths)\n",
    "                current_input = (projection_with_checkpoints * (1-masks[:, t, :]) + inputs[:, t, :] * (masks[:, t, :])).unsqueeze(1)\n",
    "        return current_input[0,0,0], current_input[0,0,1]\n",
    "    \n",
    "\n",
    "    def compute_reward(self, next_hop):\n",
    "        if self.routing_steps >= self.max_routing_steps:\n",
    "            self.routing_done = True\n",
    "            return -1\n",
    "        elif self.adj_matrix[self.current_node, self.end_node] == 1:\n",
    "            self.routing_done = True\n",
    "            return (self.min_n_hops / self.routing_steps)\n",
    "        elif self.n_hop_matrix[self.current_node, self.end_node] > self.n_hop_matrix[next_hop, self.end_node]:\n",
    "            return 0.1\n",
    "        else:\n",
    "            return -0.15\n",
    "\n",
    "\n",
    "    def get_action_mask(self):\n",
    "        action_mask = copy.deepcopy(self.prunned_adj_matrix[self.current_node])\n",
    "        action_mask = F.pad(action_mask, (0, self.n_nodes - action_mask.size(0)), \"constant\", 0).to(device)\n",
    "        return action_mask\n",
    "\n",
    "\n",
    "    def sim_done(self):\n",
    "        \"\"\"\n",
    "        function: get the done state of simulation.\n",
    "        \"\"\"\n",
    "        return not (shouldContinueSim() and self.step_counter < self.max_steps)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test the Greedy BFS on Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Retrying in 1 seconds\n",
      "***Starting server on port 48277 ***\n",
      "Loading net-file from './config/osm.net.xml.gz' ... done (117ms).\n",
      "Loading done.\n",
      "Simulation version 1.20.0 started with time: 0.00.\n",
      "Simulation ended at time: 1557.00\n",
      "Reason: TraCI requested termination.\n",
      "Performance: \n",
      " Duration: 0.38s\n",
      " TraCI-Duration: 0.23s\n",
      " Real time factor: 4097.37\n",
      " UPS: 121136.842105\n",
      "Vehicles: \n",
      " Inserted: 89\n",
      " Running: 0\n",
      " Waiting: 0\n",
      "Statistics (avg of 89):\n",
      " RouteLength: 4885.02\n",
      " Speed: 9.58\n",
      " Duration: 517.21\n",
      " WaitingTime: 17.72\n",
      " TimeLoss: 70.09\n",
      " DepartDelay: 0.47\n",
      "\n",
      " Retrying in 1 seconds\n",
      "***Starting server on port 42045 ***\n",
      "Loading net-file from './config/osm.net.xml.gz' ... done (103ms).\n",
      "Loading done.\n",
      "Simulation version 1.20.0 started with time: 0.00.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_5420/2162613853.py:273: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return self.state, torch.tensor(reward).to(device), self.routing_done\n"
     ]
    }
   ],
   "source": [
    "model = GRUModel(input_size=6, hidden_size=256, num_layers=2, output_size=2).to(device)\n",
    "# load the model\n",
    "model.load_state_dict(torch.load('models/gru_trajectory_prediction.pth'))\n",
    "model.eval()\n",
    "env = Incomplete_Routing_Gym(sumoCmd, model)\n",
    "env.reset()\n",
    "sim_done = False\n",
    "iteration = 10\n",
    "no_direct_path = 0\n",
    "total_tasks = 0\n",
    "total_reward = 0\n",
    "\n",
    "step_counter = 0\n",
    "while not sim_done:\n",
    "    state = env.next_episode()\n",
    "    step_counter = env.step_counter\n",
    "    if step_counter % 10 == 0:\n",
    "        print(\"Episode: \", step_counter)\n",
    "    if step_counter % 20 == 0:\n",
    "        print(\"No direct path: \", no_direct_path)\n",
    "        print(\"Total tasks: \", total_tasks)\n",
    "        print(\"Total reward: \", total_reward)\n",
    "    sim_done = env.sim_done()\n",
    "    for i in range(iteration):\n",
    "        state = env.next_episode(refresh=True)\n",
    "        total_tasks += 1\n",
    " \n",
    "        routing_done = False\n",
    "        episode_reward = 0\n",
    "        skip = False\n",
    "        while not routing_done:\n",
    "            action_mask = env.get_action_mask()\n",
    "            action_indices = torch.where(action_mask == 1)[0]\n",
    "\n",
    "            one_hot_distance_to_end = state.x[:, :8]\n",
    "            distance_to_end = torch.argmax(one_hot_distance_to_end, dim=1)\n",
    "            current_node = env.current_node\n",
    "            current_distance = distance_to_end[current_node]\n",
    "\n",
    "            masked_distance_to_end = distance_to_end * action_mask + 8 * (1 - action_mask)\n",
    "            closer_to_end = torch.where(masked_distance_to_end < current_distance)[0]\n",
    "            if len(closer_to_end) == 0:\n",
    "                skip = True\n",
    "                no_direct_path += 1\n",
    "                break\n",
    "            selected_action = random.choice(closer_to_end)\n",
    "            selected_action_index = int(torch.where(action_indices == selected_action)[0])\n",
    "            state, reward, routing_done = env.act(selected_action_index)\n",
    "            \n",
    "            episode_reward += reward.item()\n",
    "        if not skip:\n",
    "            total_reward += episode_reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_reward:  56.07121231406927\n",
      "total_tasks:  50\n",
      "average_reward:  1.367590544245592\n",
      "no_direct_path:  9\n"
     ]
    }
   ],
   "source": [
    "print(\"total_reward: \", total_reward)\n",
    "print(\"total_tasks: \", total_tasks)\n",
    "print(\"average_reward: \", total_reward / (total_tasks - no_direct_path))\n",
    "print(\"no_direct_path: \", no_direct_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sumo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
