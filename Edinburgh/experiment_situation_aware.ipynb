{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader, Dataset\n",
    "import sumolib\n",
    "import traci\n",
    "from sumolib import checkBinary\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch_geometric.nn import GCNConv\n",
    "from torch_geometric.data import Data\n",
    "import sys\n",
    "import io\n",
    "from contextlib import redirect_stdout\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "from utils import *\n",
    "\n",
    "\n",
    "if 'SUMO_HOME' in os.environ:\n",
    "    print('SUMO_HOME found')\n",
    "    sys.path.append(os.path.join(os.environ['SUMO_HOME'], 'tools'))\n",
    "\n",
    "sumoBinary = checkBinary('sumo-gui')\n",
    "# sumoBinary = checkBinary('sumo')\n",
    "roadNetwork = \"./config/osm.sumocfg\"\n",
    "sumoCmd = [sumoBinary, \"-c\", roadNetwork, \"--start\", \"--quit-on-end\"]\n",
    "# use gpu if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Using device: \" + str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planned_path = get_planned_path()\n",
    "path_values = list(planned_path.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example DataFrame loading\n",
    "df = pd.read_csv('edinburgh_trajectories.csv')\n",
    "num_cols = df.shape[1]\n",
    "position_indices = [i for i in range(num_cols) if i % 4 == 1 or i % 4 == 2]\n",
    "position_df = df.iloc[:, position_indices]\n",
    "position_array = position_df.to_numpy()\n",
    "sequence_length = len(position_indices) // 2\n",
    "tensor_list = []\n",
    "\n",
    "for row in position_array:\n",
    "    reshaped_tensor = torch.tensor(row.reshape(sequence_length, 2))\n",
    "    tensor_list.append(reshaped_tensor)\n",
    "\n",
    "all_trajectories_tensor = torch.stack(tensor_list) / 10\n",
    "\n",
    "def missing(x, y, z, p):\n",
    "    return torch.tensor(np.repeat(np.random.rand(x * y) < p, z).reshape(x, y, z)).float()\n",
    "\n",
    "def generate_masks(tensors, min_mask_ratio=0.2, max_mask_ratio=0.4, missing_ratio=0.5, complete_traj_ratio=0.8):\n",
    "    initial_masks = missing(tensors.shape[0], tensors.shape[1], tensors.shape[2], missing_ratio)\n",
    "    masks = []\n",
    "    for initial_mask in initial_masks:\n",
    "        if np.random.rand() < complete_traj_ratio:\n",
    "            masks.append(torch.zeros_like(initial_mask).tolist())\n",
    "            continue\n",
    "        seq_length = initial_mask.shape[0]\n",
    "        mask_start = np.random.randint(int(seq_length * min_mask_ratio), int(seq_length * max_mask_ratio))\n",
    "        mask = torch.zeros_like(initial_mask)\n",
    "        mask[:, :mask_start] = 1\n",
    "        mask = initial_mask * mask\n",
    "        mask[0] = 0\n",
    "        mask[1] = 0\n",
    "        masks.append(mask.tolist())\n",
    "    return torch.tensor(masks)\n",
    "\n",
    "# split the data into training and validation sets\n",
    "# because the data is randomly generated, we don't need to shuffle it\n",
    "train_ratio = 0.8\n",
    "train_size = int(train_ratio * all_trajectories_tensor.shape[0])\n",
    "train_trajectories_tensor = all_trajectories_tensor[:train_size]\n",
    "val_trajectories_tensor = all_trajectories_tensor[train_size:]\n",
    "\n",
    "train_path_values = torch.tensor(path_values[:train_size]) / 10\n",
    "val_path_values = torch.tensor(path_values[train_size:]) / 10\n",
    "\n",
    "train_mask = generate_masks(train_trajectories_tensor)\n",
    "\n",
    "class DatasetWithPlans(Dataset):\n",
    "    def __init__(self, tensor, input_mask, path_values):\n",
    "        self.tensor = tensor.float().to(device)\n",
    "        self.input_mask = input_mask.float().to(device)\n",
    "        self.path_values = path_values.float().to(device)\n",
    "    def __len__(self):\n",
    "        return len(self.tensor)\n",
    "    def __getitem__(self, idx):\n",
    "        return self.tensor[idx], self.input_mask[idx], self.path_values[idx]\n",
    "\n",
    "train_dataset = DatasetWithPlans(train_trajectories_tensor, train_mask, train_path_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRUModel(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, num_classes):\n",
    "        super(GRUModel, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.num_layers = num_layers\n",
    "        self.gru = nn.GRU(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc1 = nn.Linear(hidden_size, int(hidden_size/2))\n",
    "        self.fc2 = nn.Linear(int(hidden_size/2), num_classes)\n",
    "        self.relu = nn.ReLU()\n",
    "    \n",
    "    def forward(self, x, h0=None):\n",
    "        if h0 is None:\n",
    "            h0 = torch.zeros(self.num_layers, x.size(0), self.hidden_size).to(device)\n",
    "        out, hidden = self.gru(x, h0)  \n",
    "        out = self.fc1(out[:, -1, :])\n",
    "        out = self.relu(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.relu(out)\n",
    "        return out, hidden\n",
    "\n",
    "class CustomMSE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CustomMSE, self).__init__()\n",
    "\n",
    "    def forward(self, output, target):\n",
    "        # where target is 0\n",
    "        mask = (target != 0).float().to(device)\n",
    "        mse = torch.mean(((output - target) ** 2) * mask)\n",
    "        directional_diff = torch.mean(torch.abs(torch.atan2(output[:, 1], output[:, 0]) - torch.atan2(target[:, 1], target[:, 0])))\n",
    "        return mse + directional_diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def project_to_nearest(prediction, planned_path):\n",
    "    with torch.no_grad():\n",
    "        starts = planned_path[:, :-1, :]\n",
    "        to = planned_path[:, 1:, :]\n",
    "\n",
    "        prediction = prediction.unsqueeze(1).repeat(1, starts.shape[1], 1)\n",
    "        ap = prediction - starts\n",
    "        ab = to - starts\n",
    "        numerator = torch.einsum('ijk,ijk->ij', ap, ab)\n",
    "        denominator = torch.einsum('ijk,ijk->ij', ab, ab)\n",
    "        t = numerator / denominator\n",
    "        t = torch.nan_to_num(t, nan=0.0)\n",
    "        t = torch.clamp(t, 0, 1)\n",
    "        projections = starts + t.unsqueeze(2) * ab\n",
    "        diff = projections - prediction\n",
    "        distances = torch.norm(diff, dim=2)\n",
    "        min_indices = torch.argmin(distances, dim=1)\n",
    "        projections = projections[range(projections.shape[0]), min_indices]\n",
    "        return projections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, dataloader, epochs, optimizer, criterion):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        for inputs, masks, planned_path in dataloader:\n",
    "            optimizer.zero_grad()\n",
    "            hidden = None\n",
    "            loss = 0\n",
    "            # Autoregressive prediction\n",
    "            # Start with the first input and predict each subsequent step\n",
    "            seq_len = inputs.size(1)\n",
    "            current_input = inputs[:, 0, :].unsqueeze(1)\n",
    "            for t in range(1, seq_len):\n",
    "                prediction, hidden = model(current_input, hidden)\n",
    "\n",
    "                previous_input = inputs[:, t-1, :]\n",
    "                if epoch > 30:\n",
    "                    if epoch > 40:\n",
    "                        # print(t, epoch)\n",
    "                        # print(\"predicted\")\n",
    "                        # print(prediction[0])\n",
    "                        projected = project_to_nearest(prediction, planned_path)\n",
    "                        # print(\"projected\")\n",
    "                        # print(projected[0])\n",
    "                        # print(\"actual\")\n",
    "                        # print(inputs[:, t, :][0])\n",
    "                        if prediction.isnan().any():\n",
    "                            break\n",
    "                        current_input = (projected * masks[:, t, :] + inputs[:, t, :] * (1-masks[:, t, :])).unsqueeze(1)\n",
    "                    else:\n",
    "                        current_input = (prediction * masks[:, t, :] + inputs[:, t, :] * (1-masks[:, t, :])).unsqueeze(1)\n",
    "                else:\n",
    "                    current_input = inputs[:, t, :].unsqueeze(1)\n",
    "                loss += criterion(prediction - previous_input, inputs[:, t, :]-previous_input) #(current_input-previous_input).squeeze(1))\n",
    "                \n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            total_loss += loss.item()\n",
    " \n",
    "        print(f'Epoch {epoch+1}, Loss: {total_loss / len(dataloader)}')\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n",
    "model = GRUModel(input_size=2, hidden_size=128, num_layers=2, num_classes=2).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "criterion = CustomMSE()\n",
    "train_model(model, train_dataloader, 50, optimizer, criterion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def checkModel(model, inputs, masks, paths):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        hidden = None\n",
    "        seq_len = inputs.size(1)\n",
    "        current_input = inputs[:, 0, :].unsqueeze(1)\n",
    "        for t in range(1, seq_len):\n",
    "            prediction, hidden = model(current_input, hidden)\n",
    "            projected = project_to_nearest(prediction, paths)\n",
    "            current_input = (projected * masks[:, t, :] + inputs[:, t, :] * (1-masks[:, t, :])).unsqueeze(1)\n",
    "            print(projected[2], inputs[:, t, :][2])\n",
    "\n",
    "# get the first batch in dataloader\n",
    "val_mask = generate_masks(val_trajectories_tensor, missing_ratio=0.9, complete_traj_ratio=0)\n",
    "val_dataset = DatasetWithPlans(val_trajectories_tensor, val_mask, val_path_values)\n",
    "val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "inputs, masks, paths = next(iter(val_dataloader))\n",
    "\n",
    "checkModel(model, inputs, masks, paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    steps = 0\n",
    "    for inputs, masks, paths in dataloader:\n",
    "        hidden = None\n",
    "        loss = 0\n",
    "        seq_len = inputs.size(1)\n",
    "        current_input = inputs[:, 0, :].unsqueeze(1)\n",
    "        for t in range(1, seq_len):\n",
    "            new_steps = int(sum((inputs[:, t, :].reshape(-1) != 0).float().to(device))) / 2\n",
    "            if new_steps == 0:\n",
    "                break\n",
    "            steps += new_steps\n",
    "            prediction, hidden = model(current_input, hidden)\n",
    "            projected = project_to_nearest(prediction, paths)\n",
    "            current_input = (projected * masks[:, t, :] + inputs[:, t, :] * (1-masks[:, t, :])).unsqueeze(1)\n",
    "            loss += torch.norm((projected - inputs[:, t, :]) * 10, dim=1) * (inputs[:, t, :] != 0)[:, 0]\n",
    "        total_loss += loss.sum().item()\n",
    "    print(f'Validation Loss: {total_loss / steps}')\n",
    "\n",
    "for i in [0.9, 0.8, 0.7, 0.6, 0.5]:\n",
    "    val_mask = generate_masks(val_trajectories_tensor, missing_ratio=i, complete_traj_ratio=0)\n",
    "    val_dataset = DatasetWithPlans(val_trajectories_tensor, val_mask, val_path_values)\n",
    "    val_dataloader = DataLoader(val_dataset, batch_size=64, shuffle=True)\n",
    "    evaluate_model(model, val_dataloader)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
